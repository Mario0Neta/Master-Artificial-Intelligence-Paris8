{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcc99c92",
   "metadata": {},
   "source": [
    "# Using Examples (Few‑Shot Prompting)\n",
    "**Modèle** : *Llama-3.2-1B (Instruct)* via **Ollama**  \n",
    "**Objectif** : Améliorer la qualité et la stabilité des réponses en guidant le modèle avec des **exemples** (few‑shot), tout en contrôlant le style et le format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2edfbe7",
   "metadata": {},
   "source": [
    "## Pourquoi le few‑shot ?\n",
    "- **Guidage** : démontre *comment* répondre (forme, ton, granularité) plutôt que *quoi* répondre seulement.\n",
    "- **Généralisation** : le modèle imite le **pattern** fourni.\n",
    "- **Stabilité** : réduit la variabilité vs zéro‑shot, surtout pour des formats stricts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b01487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optionnel) Installer/mettre à jour le client Python Ollama\n",
    "# !pip install -q --upgrade ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e040be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ollama est accessible en local.\n",
      "⏳ Vérification/téléchargement du modèle 'llama3.2:1b'...\n",
      "✅ Modèle prêt.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "def assert_ollama_ready():\n",
    "    try:\n",
    "        _ = ollama.list()\n",
    "        print(\"✅ Ollama est accessible en local.\")\n",
    "    except Exception as e:\n",
    "        raise SystemExit(\n",
    "            \"❌ Impossible de contacter Ollama. Démarrez le serveur (ex: 'ollama serve').\\n\"\n",
    "            f\"Détails: {e}\"\n",
    "        )\n",
    "\n",
    "assert_ollama_ready()\n",
    "\n",
    "try:\n",
    "    print(\"⏳ Vérification/téléchargement du modèle 'llama3.2:1b'...\")\n",
    "    ollama.pull('llama3.2:1b')\n",
    "    print(\"✅ Modèle prêt.\")\n",
    "except Exception as e:\n",
    "    print(\"ℹ️ Vérifiez le tag (ex: 'llama3.2:1b').\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392e9755",
   "metadata": {},
   "source": [
    "## Fonctions utilitaires\n",
    "- `chat_zeroshot(user)` : baseline sans exemple.  \n",
    "- `chat_fewshot(system, shots, user)` : ajoute des **exemples** (rôle `assistant` ou paires user/assistant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e6356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Optional\n",
    "\n",
    "def chat_zeroshot(user_prompt: str, temperature: float = 0.2) -> str:\n",
    "    r = ollama.chat(model=\"llama3.2:1b\", messages=[{\"role\":\"user\",\"content\": user_prompt}], options={\"temperature\": temperature})\n",
    "    return r[\"message\"][\"content\"]\n",
    "\n",
    "def chat_fewshot(system_prompt: str, shots: List[Tuple[str, str]], user_prompt: str, temperature: float = 0.2) -> str:\n",
    "    messages = []\n",
    "    if system_prompt:\n",
    "        messages.append({\"role\":\"system\",\"content\": system_prompt})\n",
    "   \n",
    "    for u,a in shots:\n",
    "        messages.append({\"role\":\"user\",\"content\": u})\n",
    "        messages.append({\"role\":\"assistant\",\"content\": a})\n",
    "    messages.append({\"role\":\"user\",\"content\": user_prompt})\n",
    "    r = ollama.chat(model=\"llama3.2:1b\", messages=messages, options={\"temperature\": temperature})\n",
    "    return r[\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90ad1b4",
   "metadata": {},
   "source": [
    "## 1) Zéro‑shot vs Few‑shot (format imposé)\n",
    "Nous voulons un **résumé en 3 puces** avec **une phrase** par puce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41ce76b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— Zéro‑shot —\n",
      " Voici un résumé du texte en 3 puces :\n",
      "\n",
      "* Les arbres de décision sont des éléments clés qui partitionnent l'espace dans des régions homogènes.\n",
      "* Ils sont faciles à comprendre et rapides à entraîner, mais peuvent sur-apprendre sans élagage.\n",
      "* On les utilise souvent en ensemble (forêts aléatoires ou boosting) pour améliorer les performances.\n",
      "\n",
      "— Few‑shot (avec 1 exemple) —\n",
      " - Les arbres de décision sont des structures d'apprentissage automatique.\n",
      "- Ils partitionnent l'espace des caractéristiques en régions homogènes.\n",
      "- On les utilise pour améliorer la performance des modèles de classification et d'analyse.\n"
     ]
    }
   ],
   "source": [
    "text = (\n",
    "    \"Les arbres de décision partitionnent l'espace des caractéristiques en régions homogènes. \"\n",
    "    \"Ils sont lisibles, rapides à entraîner, mais peuvent sur‑apprendre sans élagage. \"\n",
    "    \"On les utilise aussi en ensembles (forêts aléatoires, boosting) pour de meilleures performances.\"\n",
    ")\n",
    "user_q = f\"Résume ce texte en 3 puces, une phrase par puce. Texte: {text}\"\n",
    "print(\"— Zéro‑shot —\\n\", chat_zeroshot(user_q))\n",
    "\n",
    "system_rule = \"Tu es un formateur concis. Sortie: exactement 3 puces, une phrase par puce.\"\n",
    "shots = [\n",
    "    (\"Résume: 'Le k‑NN classe par proximité moyenne.'\",\n",
    "     \"- Méthode paresseuse basée sur la proximité des exemples.\\n- Performance sensible au choix de k et à la normalisation.\\n- Utile quand la frontière est non linéaire et que les données sont locales.\"),\n",
    "]\n",
    "print(\"\\n— Few‑shot (avec 1 exemple) —\\n\", chat_fewshot(system_rule, shots, user_q))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fe87ae",
   "metadata": {},
   "source": [
    "## 2) Style transfer par l’exemple\n",
    "Nous voulons un style **humoristique** et **grand public**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "795d6e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les réseaux de neurones sont des systèmes informatiques qui apprennent à reconnaitre et à comprendre les données en utilisant des connexions artificielles. Ils fonctionnent comme un réseau d'informateurs qui échangent des informations, ce qui leur permet de prendre des décisions ou d'apprendre de nouvelles choses. Les réseaux de neurones sont souvent utilisés dans les applications de traitement du langage naturel, la reconnaissance d'images et le traitement des données sensorielles.\n"
     ]
    }
   ],
   "source": [
    "system_style = \"Tu écris pour le grand public, ton léger et analogies simples. 3 phrases.\"\n",
    "shots = [\n",
    "    (\"Explique le sur‑apprentissage.\",\n",
    "     \"Imagine un élève qui mémorise chaque réponse sans comprendre: il cartonne en devoir maison mais panique à l'exam. \"\n",
    "     \"Un modèle sur‑apprend pareil: super sur les données vues, nul sur le reste. \"\n",
    "     \"La solution: plus de données, régularisation, et un peu d'humilité.\")\n",
    "]\n",
    "user_q = \"Explique les réseaux de neurones en 3 phrases.\"\n",
    "print(chat_fewshot(system_style, shots, user_q, temperature=0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff82c7c",
   "metadata": {},
   "source": [
    "## 3) Sorties structurées guidées par exemples\n",
    "On exige un **JSON** avec clés `definition`, `use_cases` (3), `risk` (1 phrase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb1d69bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"name\": \"Transformers\",\n",
      "  \"description\": \"Modèle de traitement automatique du langage à base d'apprentissage automatique et de réseaux de neurones.\",\n",
      "  \"use_cases\": [\n",
      "    \"Recherche d'entraînement des modèles de langage\",\n",
      "    \"Analyse de texte\",\n",
      "    \"Réduction de la taille des données\"\n",
      "  ],\n",
      "  \"risk\": {\n",
      "    \"sensibilité\": \"Élevée\",\n",
      "    \"hypothèses d'indépendance\": \"Faible\",\n",
      "    \"données partielles\": \"Faible\"\n",
      "  }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "system_json = \"Tu es un générateur de JSON strict. Réponds uniquement par un objet JSON valide.\"\n",
    "shots = [\n",
    "    (\n",
    "        \"Donne un JSON pour 'Réseau bayésien' avec les mêmes clés.\",\n",
    "        '{\"definition\":\"Modèle probabiliste à graphes orientés représentant des dépendances.\",'\n",
    "        '\"use_cases\":[\"diagnostic médical\",\"détection d\\'anomalies\",\"aide à la décision\"],'\n",
    "        '\"risk\":\"Sensibilité aux hypothèses d\\'indépendance et aux données partielles.\"}'\n",
    "    )\n",
    "]\n",
    "user_q = \"Donne un JSON pour 'Transformers' avec les mêmes clés.\"\n",
    "print(chat_fewshot(system_json, shots, user_q, temperature=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653d3563",
   "metadata": {},
   "source": [
    "## 4) Contre‑exemples (negative shots)\n",
    "Fournir un exemple **à ne pas imiter** peut clarifier le style attendu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b2e95fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voici une explication du café en 4 puces :\n",
      "\n",
      "*   Le café est un produit alimentaire résultant de la fermentation des graines moulues.\n",
      "*   Il est généralement consommé chaud, souvent accompagné d'un petit déjeuner ou d'une pause après le travail.\n",
      "*   Le café contient une grande quantité de caféine, qui peut avoir des effets stimulants sur l'organisme.\n"
     ]
    }
   ],
   "source": [
    "system_neg = (\n",
    "    \"Tu es un rédacteur technique. Évite le jargon inutile. Sortie: 4 puces, phrases courtes.\"\n",
    ")\n",
    "shots = [\n",
    "    (\"Mauvais style: explication verbeuse et compliquée.\",\n",
    "     \"(À éviter) Le café, décoction aromatique résultant de la percolation aqueuse à haute température...\"),\n",
    "    (\"Bon style: 4 puces, phrases simples.\",\n",
    "     \"- Boisson chaude.\\n- Fait à partir de grains moulus.\\n- Donne de l’énergie.\\n- Trop en boire empêche de dormir.\"),\n",
    "]\n",
    "\n",
    "user_q = \"Explique le café en 4 puces.\"\n",
    "print(chat_fewshot(system_neg, shots, user_q, temperature=0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78af7231",
   "metadata": {},
   "source": [
    "## 5) Nombre d’exemples & ordre\n",
    "- Trop d’exemples peut **allonger** et **diluer** l’instruction.\n",
    "- L’**ordre** des exemples influence souvent le style final (effet de récence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a553ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— 1 shot —\n",
      " Le dropout est un concept clé dans l'apprentissage automatique et les réseaux de neurones artificiels (RNN). Il s'agit d'une technique utilisée pour supprimer certaines unités ou des lignes du réseau, généralement pour éviter les \"pentes\" ou les \"déviations\" non prévisibles.\n",
      "\n",
      "En général, le dropout est appliqué à un réseau de neurones artificiels lorsqu'il est entraîné sur une grande quantité d'entraînement. Lorsque le réseau est entraîné, il peut apprendre à reconnaître des modèles dans les données, mais cela peut également conduire à la généralisation excessive et à l'apparition de \"déviations\" non prévisibles.\n",
      "\n",
      "Le dropout permet de supprimer ces déviations en sélectionnant aléatoirement certaines unités du réseau pour ne pas les entraîner. Cela aide à :\n",
      "\n",
      "- Améliorer la stabilité du modèle\n",
      "- Réduire l'overfitting (apparition excessive d'un modèle sur un ensemble de données)\n",
      "- Augmenter la généralisation\n",
      "\n",
      "Le dropout est souvent utilisé dans les réseaux de neurones artificiels, notamment dans les architectures basées sur le réseau de neurones convoluant (CNN) et les réseaux de neurones recurrents (RNN).\n",
      "\n",
      "— 3 shots —\n",
      " - Évite les perturbations.\n",
      "- Augmente l'efficacité.\n",
      "- Réduit le sur-apprentissage.\n"
     ]
    }
   ],
   "source": [
    "system_rule = \"Tu réponds en 3 puces, ton pédagogique.\"\n",
    "shots1 = [\n",
    "    (\"Explique le gradient.\", \"- Direction d\\'amélioration.\\n- Calcule la pente.\\n- Guide la mise à jour.\"),\n",
    "]\n",
    "shots3 = [\n",
    "    (\"Explique la régularisation.\", \"- Pénalise la complexité.\\n- Réduit le sur‑apprentissage.\\n- Améliore la généralisation.\"),\n",
    "    (\"Explique la validation croisée.\", \"- Sépare entraînement/validation.\\n- Évalue la robustesse.\\n- Aide au choix d\\'hyperparamètres.\"),\n",
    "    (\"Explique le taux d\\'apprentissage.\", \"- Contrôle la taille des pas.\\n- Trop grand: diverge.\\n- Trop petit: lent.\"),\n",
    "]\n",
    "user_q = \"Explique le dropout.\"\n",
    "print(\"— 1 shot —\\n\", chat_fewshot(system_rule, shots1, user_q))\n",
    "print(\"\\n— 3 shots —\\n\", chat_fewshot(system_rule, shots3, user_q))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176b8446",
   "metadata": {},
   "source": [
    "## 6) Pièges courants & bonnes pratiques\n",
    "- **Sur‑contrainte** : n’écrasez pas la flexibilité si la tâche est ouverte.\n",
    "- **Exemples biaisés** : diversifiez pour éviter une sortie trop uniforme.\n",
    "- **Hallucination de format** : répétez les clés exactes dans les exemples.\n",
    "- **Trop de shots** : coût/latence ↑ ; privilégiez 1–3 exemples pertinents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bd39d2",
   "metadata": {},
   "source": [
    "## Template few‑shot réutilisable\n",
    "System: « Tu es <persona>. Sortie: <format>. Contraintes: <N puces / M phrases / JSON>. »\n",
    "\n",
    "Exemple user → assistant #1\n",
    "- User: <entrée‑exemple>\n",
    "- Assistant: <sortie‑exemple>\n",
    "\n",
    "Exemple user → assistant #2 (optionnel)\n",
    "\n",
    "User (nouvelle entrée): <votre question>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd8d8c2",
   "metadata": {},
   "source": [
    "## À retenir (Phase 5)\n",
    "- Le **few‑shot** montre des **patrons** (format, ton) à imiter.  \n",
    "- 1–3 exemples **bien choisis** suffisent souvent.  \n",
    "- Combinez avec les phases 2–4 : persona (system), séparation data/instructions, format strict.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9868c430",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
