{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdf76b06",
   "metadata": {},
   "source": [
    "\n",
    "# Section 2 — Dense Vector Retrieval (avec Hugging Face)\n",
    "\n",
    "Ce notebook illustre la **récupération dense** : on représente requêtes et documents par des **vecteurs continus** (*embeddings*), puis on cherche les **voisins les plus proches**.  \n",
    "L'objectif est de capturer le **sens** (sémantique) au-delà du simple recouvrement de termes.\n",
    "\n",
    "**Plan :**\n",
    "1. **Génération d'embeddings**  \n",
    "   - Rappel rapide : *Word2Vec*, *GloVe* (mots) → moyennage pour phrases.  \n",
    "   - Embeddings de **phrases** avec des modèles *Hugging Face* (*Sentence-Transformers*).\n",
    "2. **Indexation & Recherche** (k-NN, FAISS).  \n",
    "3. **Re-ranking** avec un **Cross-Encoder** (HF) pour améliorer l'ordre des résultats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0d5344",
   "metadata": {},
   "source": [
    "\n",
    "## Pré-requis (installation)\n",
    "Exécuter la cellule suivante **une seule fois** pour installer les dépendances si nécessaire.  \n",
    "> Si vous êtes hors-ligne, laissez-la de côté et lisez simplement le code/exemples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf9350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optionnel : décommentez pour installer\n",
    "# %pip -q install --upgrade pip\n",
    "# %pip -q install sentence-transformers faiss-cpu gensim torch --extra-index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7302a079",
   "metadata": {},
   "source": [
    "\n",
    "## Données d'exemple\n",
    "On réutilise un mini-corpus multi-lingue proche de la Section 1 et quelques requêtes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b79ae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "\n",
    "# Un mini-corpus jouet (FR + un peu d'EN pour montrer la robustesse)\n",
    "corpus = [\n",
    "    # --- Concepts généraux & définitions ---\n",
    "    \"La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\",\n",
    "    \"Un pipeline RI comporte souvent : prétraitement, indexation, pondération, scoring, puis évaluation des résultats.\",\n",
    "    \"Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\",\n",
    "    \"TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\",\n",
    "    \"Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\",\n",
    "    \"BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\",\n",
    "    \"Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\",\n",
    "    \"La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\",\n",
    "    \"RAG (Retrieval-Augmented Generation) combine récupération de passages et modèles génératifs pour produire des réponses sourcées.\",\n",
    "    \"La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\",\n",
    "\n",
    "    # --- Prétraitement & normalisation ---\n",
    "    \"La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\",\n",
    "    \"Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\",\n",
    "    \"La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\",\n",
    "    \"Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\",\n",
    "    \"Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\",\n",
    "    \"Les entités nommées (NER) aident à conserver des unités sémantiques comme 'OpenAI' ou 'Europe/Paris'.\",\n",
    "\n",
    "    # --- Outils & bibliothèques ---\n",
    "    \"Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\",\n",
    "    \"Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\",\n",
    "    \"FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\",\n",
    "    \"Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\",\n",
    "    \"Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\",\n",
    "\n",
    "    # --- Évaluation ---\n",
    "    \"L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\",\n",
    "    \"MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\",\n",
    "    \"Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\",\n",
    "    \"La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\",\n",
    "    \"Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\",\n",
    "\n",
    "    # --- Multilingue & domaines ---\n",
    "    \"Les requêtes peuvent être multilingues ; les modèles multilingues mappent plusieurs langues dans le même espace.\",\n",
    "    \"Dans le domaine médical, la précision terminologique est cruciale (ex. 'hypertension artérielle').\",\n",
    "    \"En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\",\n",
    "    \"Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\",\n",
    "    \"La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\",\n",
    "\n",
    "    # --- Bruit, longueur et structure ---\n",
    "    \"Certains documents sont très courts: 'BM25 expliqué rapidement'.\",\n",
    "    \"D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\",\n",
    "    \"URLs et hashtags (#IR, #NLP) perturbent parfois la segmentation en tokens.\",\n",
    "    \"Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\",\n",
    "\n",
    "    # --- Recherche hybride & reranking ---\n",
    "    \"La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\",\n",
    "    \"Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\",\n",
    "    \"La réduction de dimension (PCA) ou la quantification des vecteurs (PQ, IVFPQ) accélère l'ANN au prix d'une légère perte de rappel.\",\n",
    "    \"Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\",\n",
    "    \"La désambiguïsation des acronymes (ex. 'IR' = 'information retrieval' ou 'imagerie par résonance') dépend du contexte.\",\n",
    "\n",
    "    # --- Cas concrets & exemples mixtes ---\n",
    "    \"Le sac de mots (bag of words) est simple et robuste mais ne capture pas la sémantique profonde.\",\n",
    "    \"TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\",\n",
    "    \"Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\",\n",
    "    \"Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\",\n",
    "    \"La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\",\n",
    "    \"Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\",\n",
    "    \"L'alignement d'espaces multilingues permet 'apprentissage' ≈ 'learning' ≈ 'aprendizaje'.\",\n",
    "    \"Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\",\n",
    "    \"Le choix des stop words en français diffère de l'anglais (ex. 'au', 'aux', 'des', 'du').\",\n",
    "    \"Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\",\n",
    "    \"La normalisation Unicode (NFC/NFKD) affecte le traitement des diacritiques (é/ê/e).\",\n",
    "    \"En RAG, l'ordre : retrieve → read → generate ; la qualité du retrieve détermine souvent 80% du succès perçu.\",\n",
    "    \"Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\"\n",
    "]\n",
    "\n",
    "queries = [\n",
    "    # Requêtes ciblées IR\n",
    "    \"comment fonctionne BM25 (k1, b) pour le ranking ?\",\n",
    "    \"différence entre sac de mots et TF-IDF\",\n",
    "    \"CountVectorizer vs TfidfVectorizer scikit-learn\",\n",
    "    \"bm25 ranking vs dense retrieval\",\n",
    "    \"quels avantages des embeddings denses pour la sémantique ?\",\n",
    "\n",
    "    # Prétraitement & robustesse\n",
    "    \"liste de stopwords en français et impact sur la précision\",\n",
    "    \"lemmatisation vs stemming pour le français\",\n",
    "    \"normalisation des accents et diacritiques\",\n",
    "    \"gerer les fautes de frappe en recherche d'information\",\n",
    "    \"traiter les hashtags et urls dans les documents\",\n",
    "\n",
    "    # Évaluation\n",
    "    \"comparer MAP, MRR et nDCG@10\",\n",
    "    \"datasets d'évaluation: TREC, MS MARCO, BEIR\",\n",
    "    \"pooling et jugement de pertinence gradué\",\n",
    "    \"quelle métrique pour la pertinence multi-niveaux ?\",\n",
    "\n",
    "    # Multilingue & domaines\n",
    "    \"recherche multilingue avec SBERT ou E5\",\n",
    "    \"RAG pour questions médicales\",\n",
    "    \"désambiguïser l'acronyme IR selon le contexte\",\n",
    "    \"recherche juridique: articles et alinéas\",\n",
    "    \"recettes: pondération TF simple vs BM25\",\n",
    "\n",
    "    # ANN & systèmes\n",
    "    \"HNSW vs FAISS vs Annoy pour ANN\",\n",
    "    \"hybrid search: combiner BM25 et embeddings\",\n",
    "    \"cross-encoder pour reranking des top-k\",\n",
    "    \"quantification des vecteurs (IVFPQ) et rappels\",\n",
    "    \"pondérer le champ title plus que body\",\n",
    "\n",
    "    # Requêtes bruitées / mixtes / typos\n",
    "    \"tf–idf (variante typographique) explication\",\n",
    "    \"embeding denses (typo) utilité\",\n",
    "    \"Okapi-BM25 formule\",\n",
    "    \"vector search sparse or dense\",\n",
    "    \"BM25 sans normalisation de longueur\"\n",
    "]\n",
    "\n",
    "def show_topk(query: str, doc_ids: np.ndarray, scores: np.ndarray, k: int = 5):\n",
    "    print(f\"\\nQuery: {query!r}\")\n",
    "    print(\"-\" * 80)\n",
    "    order = np.argsort(scores)[::-1][:k]\n",
    "    for r, i in enumerate(order, 1):\n",
    "        print(f\"[{r:>2}] score={scores[i]:.4f}  doc#{doc_ids[i]} → {corpus[doc_ids[i]]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4457c7d",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Génération d'embeddings — notions clés\n",
    "\n",
    "- **Word2Vec / GloVe** : embeddings **de mots** appris à partir de co-occurrences (statistiques).  \n",
    "  Pour obtenir un embedding de phrase/document : on peut **moyenner** les vecteurs des mots (simple mais efficace).  \n",
    "- **BERT & dérivés** : modèles **contextuels** (chaque mot dépend du contexte). Pour des embeddings de *phrase*, on utilise\n",
    "  des modèles **Sentence-Transformers** spécialement *finetunés* pour la similarité sémantique.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c883f2",
   "metadata": {},
   "source": [
    "\n",
    "### 1.A — Démo rapide **Word2Vec** (toy) avec `gensim`\n",
    "\n",
    "On entraîne un mini **Word2Vec** sur notre corpus (ridiculement petit) pour illustrer la mécanique, puis on crée des embeddings de documents par **moyenne** de mots.\n",
    "> Cela **n'est pas** un modèle de qualité — c'est juste un *exemple pédagogique*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccd4d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: 'comment fonctionne BM25 (k1, b) pour le ranking ?'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9542  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 2] score=0.9359  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=0.8778  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 4] score=0.8769  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 5] score=0.8690  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "\n",
      "Query: 'différence entre sac de mots et TF-IDF'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9414  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 2] score=0.9380  doc#40 → Le sac de mots (bag of words) est simple et robuste mais ne capture pas la sémantique profonde.\n",
      "[ 3] score=0.8963  doc#41 → TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 4] score=0.8959  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 5] score=0.8713  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "\n",
      "Query: 'CountVectorizer vs TfidfVectorizer scikit-learn'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9739  doc#16 → Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "[ 2] score=0.9253  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 3] score=0.8526  doc#8 → RAG (Retrieval-Augmented Generation) combine récupération de passages et modèles génératifs pour produire des réponses sourcées.\n",
      "[ 4] score=0.8005  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 5] score=0.7814  doc#15 → Les entités nommées (NER) aident à conserver des unités sémantiques comme 'OpenAI' ou 'Europe/Paris'.\n",
      "\n",
      "Query: 'bm25 ranking vs dense retrieval'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9564  doc#20 → Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 2] score=0.9164  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 3] score=0.9072  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 4] score=0.8993  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 5] score=0.8845  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "\n",
      "Query: 'quels avantages des embeddings denses pour la sémantique ?'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9731  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 2] score=0.9266  doc#6 → Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "[ 3] score=0.9090  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 4] score=0.8838  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 5] score=0.8720  doc#20 → Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "\n",
      "Query: 'liste de stopwords en français et impact sur la précision'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9241  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 2] score=0.9180  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 3] score=0.9146  doc#10 → La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "[ 4] score=0.9045  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 5] score=0.9019  doc#28 → En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "\n",
      "Query: 'lemmatisation vs stemming pour le français'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9588  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 2] score=0.9028  doc#10 → La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "[ 3] score=0.8974  doc#13 → Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "[ 4] score=0.8864  doc#50 → La normalisation Unicode (NFC/NFKD) affecte le traitement des diacritiques (é/ê/e).\n",
      "[ 5] score=0.8784  doc#12 → La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "\n",
      "Query: 'normalisation des accents et diacritiques'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9797  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 2] score=0.9434  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 3] score=0.9421  doc#10 → La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "[ 4] score=0.9379  doc#50 → La normalisation Unicode (NFC/NFKD) affecte le traitement des diacritiques (é/ê/e).\n",
      "[ 5] score=0.9356  doc#32 → D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "\n",
      "Query: \"gerer les fautes de frappe en recherche d'information\"\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9654  doc#14 → Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 2] score=0.9024  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 3] score=0.9001  doc#28 → En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "[ 4] score=0.8980  doc#38 → Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "[ 5] score=0.8960  doc#16 → Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "\n",
      "Query: 'traiter les hashtags et urls dans les documents'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9167  doc#14 → Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 2] score=0.9148  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 3] score=0.9052  doc#16 → Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "[ 4] score=0.9031  doc#6 → Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "[ 5] score=0.9007  doc#38 → Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "\n",
      "Query: 'comparer MAP, MRR et nDCG@10'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9810  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 2] score=0.9581  doc#22 → MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "[ 3] score=0.7784  doc#48 → Le choix des stop words en français diffère de l'anglais (ex. 'au', 'aux', 'des', 'du').\n",
      "[ 4] score=0.7514  doc#28 → En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "[ 5] score=0.7398  doc#23 → Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "\n",
      "Query: \"datasets d'évaluation: TREC, MS MARCO, BEIR\"\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9777  doc#23 → Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 2] score=0.8755  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 3] score=0.8672  doc#32 → D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "[ 4] score=0.8670  doc#29 → Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "[ 5] score=0.8531  doc#52 → Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "\n",
      "Query: 'pooling et jugement de pertinence gradué'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9326  doc#30 → La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\n",
      "[ 2] score=0.9257  doc#25 → Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "[ 3] score=0.8917  doc#28 → En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "[ 4] score=0.8892  doc#9 → La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "[ 5] score=0.8831  doc#7 → La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "\n",
      "Query: 'quelle métrique pour la pertinence multi-niveaux ?'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9408  doc#9 → La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "[ 2] score=0.9310  doc#7 → La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 3] score=0.9271  doc#25 → Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "[ 4] score=0.9204  doc#30 → La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\n",
      "[ 5] score=0.8919  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "\n",
      "Query: 'recherche multilingue avec SBERT ou E5'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9098  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 2] score=0.8874  doc#7 → La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 3] score=0.8639  doc#30 → La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\n",
      "[ 4] score=0.8636  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 5] score=0.8558  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "\n",
      "Query: 'RAG pour questions médicales'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8960  doc#8 → RAG (Retrieval-Augmented Generation) combine récupération de passages et modèles génératifs pour produire des réponses sourcées.\n",
      "[ 2] score=0.8531  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 3] score=0.8479  doc#16 → Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "[ 4] score=0.8269  doc#39 → La désambiguïsation des acronymes (ex. 'IR' = 'information retrieval' ou 'imagerie par résonance') dépend du contexte.\n",
      "[ 5] score=0.8259  doc#0 → La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "\n",
      "Query: \"désambiguïser l'acronyme IR selon le contexte\"\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9351  doc#33 → URLs et hashtags (#IR, #NLP) perturbent parfois la segmentation en tokens.\n",
      "[ 2] score=0.9236  doc#39 → La désambiguïsation des acronymes (ex. 'IR' = 'information retrieval' ou 'imagerie par résonance') dépend du contexte.\n",
      "[ 3] score=0.9170  doc#0 → La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "[ 4] score=0.8710  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 5] score=0.8665  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "\n",
      "Query: 'recherche juridique: articles et alinéas'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9720  doc#28 → En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "[ 2] score=0.9022  doc#20 → Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 3] score=0.8857  doc#14 → Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 4] score=0.8733  doc#18 → FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "[ 5] score=0.8486  doc#23 → Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "\n",
      "Query: 'recettes: pondération TF simple vs BM25'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9362  doc#29 → Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "[ 2] score=0.9358  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 3] score=0.9042  doc#40 → Le sac de mots (bag of words) est simple et robuste mais ne capture pas la sémantique profonde.\n",
      "[ 4] score=0.8765  doc#41 → TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 5] score=0.8630  doc#1 → Un pipeline RI comporte souvent : prétraitement, indexation, pondération, scoring, puis évaluation des résultats.\n",
      "\n",
      "Query: 'HNSW vs FAISS vs Annoy pour ANN'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9625  doc#18 → FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "[ 2] score=0.8980  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 3] score=0.8891  doc#16 → Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "[ 4] score=0.8733  doc#38 → Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "[ 5] score=0.8494  doc#37 → La réduction de dimension (PCA) ou la quantification des vecteurs (PQ, IVFPQ) accélère l'ANN au prix d'une légère perte de rappel.\n",
      "\n",
      "Query: 'hybrid search: combiner BM25 et embeddings'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9646  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 2] score=0.9565  doc#20 → Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 3] score=0.9054  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 4] score=0.8908  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 5] score=0.8854  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "\n",
      "Query: 'cross-encoder pour reranking des top-k'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9806  doc#36 → Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "[ 2] score=0.8281  doc#14 → Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 3] score=0.8200  doc#13 → Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "[ 4] score=0.8005  doc#39 → La désambiguïsation des acronymes (ex. 'IR' = 'information retrieval' ou 'imagerie par résonance') dépend du contexte.\n",
      "[ 5] score=0.7960  doc#0 → La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "\n",
      "Query: 'quantification des vecteurs (IVFPQ) et rappels'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9672  doc#37 → La réduction de dimension (PCA) ou la quantification des vecteurs (PQ, IVFPQ) accélère l'ANN au prix d'une légère perte de rappel.\n",
      "[ 2] score=0.8930  doc#23 → Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 3] score=0.8640  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 4] score=0.8630  doc#12 → La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "[ 5] score=0.8510  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "\n",
      "Query: 'pondérer le champ title plus que body'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9892  doc#38 → Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "[ 2] score=0.9072  doc#18 → FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "[ 3] score=0.8765  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 4] score=0.8364  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 5] score=0.8345  doc#6 → Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "\n",
      "Query: 'tf–idf (variante typographique) explication'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9788  doc#41 → TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 2] score=0.8741  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 3] score=0.7826  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 4] score=0.7491  doc#40 → Le sac de mots (bag of words) est simple et robuste mais ne capture pas la sémantique profonde.\n",
      "[ 5] score=0.7484  doc#49 → Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\n",
      "\n",
      "Query: 'embeding denses (typo) utilité'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9757  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 2] score=0.8595  doc#6 → Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "[ 3] score=0.8103  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 4] score=0.7910  doc#38 → Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "[ 5] score=0.7724  doc#14 → Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "\n",
      "Query: 'Okapi-BM25 formule'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9715  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 2] score=0.9416  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=0.9020  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 4] score=0.8606  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 5] score=0.8507  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "\n",
      "Query: 'vector search sparse or dense'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9854  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 2] score=0.9742  doc#7 → La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 3] score=0.8701  doc#25 → Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "[ 4] score=0.8402  doc#9 → La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "[ 5] score=0.8292  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "\n",
      "Query: 'BM25 sans normalisation de longueur'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9673  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 2] score=0.9671  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 3] score=0.9478  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 4] score=0.9107  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 5] score=0.8962  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "\n",
    "tokenized = [simple_preprocess(doc) for doc in corpus]\n",
    "\n",
    "\n",
    "w2v = Word2Vec(sentences=tokenized, vector_size=64, window=5, min_count=1, workers=1, sg=1, epochs=100)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def doc_embedding_w2v(tokens: List[str]) -> np.ndarray:\n",
    "    vecs = [w2v.wv[t] for t in tokens if t in w2v.wv]\n",
    "    if not vecs:\n",
    "        return np.zeros(w2v.vector_size, dtype=float)\n",
    "    v = np.mean(vecs, axis=0)\n",
    "    # Normalisation pour cosinus\n",
    "    n = np.linalg.norm(v) + 1e-9\n",
    "    return v / n\n",
    "\n",
    "doc_vecs_w2v = np.vstack([doc_embedding_w2v(tok) for tok in tokenized])\n",
    "\n",
    "def search_w2v(query: str, top_k: int = 5):\n",
    "    q_vec = doc_embedding_w2v(simple_preprocess(query)).reshape(1, -1)\n",
    "    scores = (doc_vecs_w2v @ q_vec.T).ravel()  # produit scalaire \n",
    "    ids = np.arange(len(corpus))\n",
    "    show_topk(query, ids, scores, k=top_k)\n",
    "\n",
    "for q in queries:\n",
    "    search_w2v(q, top_k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d9e58d",
   "metadata": {},
   "source": [
    "\n",
    "### 1.B — **Embeddings de phrases** avec *Hugging Face* / `sentence-transformers`\n",
    "\n",
    "On utilise un modèle pré entrainer sur la langue francaise pour bien gérer le français, par exemple :\n",
    "- `camembert` (rapide, polyvalent).\n",
    "\n",
    "\n",
    "\n",
    "Le pipeline de base :\n",
    "1. Charger le modèle d'embeddings.\n",
    "2. Encoder le corpus → matrice `D × dim`.\n",
    "3. Encoder la requête et calculer la **similarité cosinus**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7723bdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name almanach/camembert-base. Creating a new one with mean pooling.\n",
      "c:\\Users\\salah\\anaconda3\\envs\\ragllm\\lib\\site-packages\\transformers\\models\\camembert\\modeling_camembert.py:388: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: 'comment fonctionne BM25 (k1, b) pour le ranking ?'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9269  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 2] score=0.9213  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=0.9180  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 4] score=0.9060  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 5] score=0.9048  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "\n",
      "Query: 'différence entre sac de mots et TF-IDF'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9239  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 2] score=0.9192  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 3] score=0.9170  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 4] score=0.9109  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 5] score=0.9034  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "\n",
      "Query: 'CountVectorizer vs TfidfVectorizer scikit-learn'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9581  doc#16 → Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "[ 2] score=0.9300  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 3] score=0.9037  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 4] score=0.8915  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 5] score=0.8845  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "\n",
      "Query: 'bm25 ranking vs dense retrieval'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8900  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 2] score=0.8831  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 3] score=0.8793  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 4] score=0.8756  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 5] score=0.8751  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "\n",
      "Query: 'quels avantages des embeddings denses pour la sémantique ?'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9126  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 2] score=0.9114  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 3] score=0.9029  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 4] score=0.9024  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 5] score=0.8976  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "\n",
      "Query: 'liste de stopwords en français et impact sur la précision'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9003  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 2] score=0.8925  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 3] score=0.8913  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 4] score=0.8808  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 5] score=0.8797  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "\n",
      "Query: 'lemmatisation vs stemming pour le français'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8726  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 2] score=0.8513  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 3] score=0.8487  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 4] score=0.8350  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 5] score=0.8335  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "\n",
      "Query: 'normalisation des accents et diacritiques'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8469  doc#12 → La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "[ 2] score=0.8211  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 3] score=0.7964  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 4] score=0.7857  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 5] score=0.7788  doc#29 → Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "\n",
      "Query: \"gerer les fautes de frappe en recherche d'information\"\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8342  doc#0 → La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "[ 2] score=0.8212  doc#14 → Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 3] score=0.8175  doc#51 → En RAG, l'ordre : retrieve → read → generate ; la qualité du retrieve détermine souvent 80% du succès perçu.\n",
      "[ 4] score=0.8134  doc#12 → La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "[ 5] score=0.8108  doc#27 → Dans le domaine médical, la précision terminologique est cruciale (ex. 'hypertension artérielle').\n",
      "\n",
      "Query: 'traiter les hashtags et urls dans les documents'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8887  doc#26 → Les requêtes peuvent être multilingues ; les modèles multilingues mappent plusieurs langues dans le même espace.\n",
      "[ 2] score=0.8810  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 3] score=0.8714  doc#49 → Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\n",
      "[ 4] score=0.8707  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 5] score=0.8668  doc#33 → URLs et hashtags (#IR, #NLP) perturbent parfois la segmentation en tokens.\n",
      "\n",
      "Query: 'comparer MAP, MRR et nDCG@10'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9149  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 2] score=0.9102  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 3] score=0.8902  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 4] score=0.8868  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 5] score=0.8825  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "\n",
      "Query: \"datasets d'évaluation: TREC, MS MARCO, BEIR\"\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9271  doc#23 → Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 2] score=0.8983  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 3] score=0.8925  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 4] score=0.8920  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 5] score=0.8897  doc#18 → FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "\n",
      "Query: 'pooling et jugement de pertinence gradué'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9047  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 2] score=0.8997  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=0.8667  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 4] score=0.8658  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 5] score=0.8655  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "\n",
      "Query: 'quelle métrique pour la pertinence multi-niveaux ?'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8936  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 2] score=0.8884  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 3] score=0.8824  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 4] score=0.8810  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 5] score=0.8798  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "\n",
      "Query: 'recherche multilingue avec SBERT ou E5'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9004  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 2] score=0.8965  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 3] score=0.8909  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 4] score=0.8825  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 5] score=0.8740  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "\n",
      "Query: 'RAG pour questions médicales'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8552  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 2] score=0.8232  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 3] score=0.8157  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 4] score=0.7960  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 5] score=0.7911  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "\n",
      "Query: \"désambiguïser l'acronyme IR selon le contexte\"\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8617  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 2] score=0.8537  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 3] score=0.8501  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 4] score=0.8470  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 5] score=0.8469  doc#49 → Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\n",
      "\n",
      "Query: 'recherche juridique: articles et alinéas'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8948  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 2] score=0.8669  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 3] score=0.8631  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 4] score=0.8595  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 5] score=0.8417  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "\n",
      "Query: 'recettes: pondération TF simple vs BM25'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8767  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 2] score=0.8719  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 3] score=0.8689  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 4] score=0.8606  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 5] score=0.8450  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "\n",
      "Query: 'HNSW vs FAISS vs Annoy pour ANN'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8899  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 2] score=0.8859  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 3] score=0.8775  doc#18 → FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "[ 4] score=0.8672  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 5] score=0.8662  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "\n",
      "Query: 'hybrid search: combiner BM25 et embeddings'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9280  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 2] score=0.9055  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 3] score=0.8965  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 4] score=0.8954  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 5] score=0.8947  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "\n",
      "Query: 'cross-encoder pour reranking des top-k'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9233  doc#36 → Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "[ 2] score=0.9114  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 3] score=0.8995  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 4] score=0.8938  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 5] score=0.8864  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "\n",
      "Query: 'quantification des vecteurs (IVFPQ) et rappels'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9162  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 2] score=0.8954  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 3] score=0.8910  doc#23 → Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 4] score=0.8901  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 5] score=0.8886  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "\n",
      "Query: 'pondérer le champ title plus que body'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8925  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 2] score=0.8849  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 3] score=0.8818  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 4] score=0.8794  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 5] score=0.8759  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "\n",
      "Query: 'tf–idf (variante typographique) explication'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9127  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 2] score=0.9024  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 3] score=0.8991  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 4] score=0.8987  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 5] score=0.8954  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "\n",
      "Query: 'embeding denses (typo) utilité'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9070  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 2] score=0.9028  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 3] score=0.8980  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 4] score=0.8900  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 5] score=0.8851  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "\n",
      "Query: 'Okapi-BM25 formule'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8676  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 2] score=0.8619  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 3] score=0.8457  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 4] score=0.8394  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 5] score=0.8221  doc#16 → Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "\n",
      "Query: 'vector search sparse or dense'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8926  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 2] score=0.8869  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 3] score=0.8630  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 4] score=0.8593  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 5] score=0.8533  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "\n",
      "Query: 'BM25 sans normalisation de longueur'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9022  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 2] score=0.8960  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=0.8801  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 4] score=0.8768  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 5] score=0.8668  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# %pip -q install sentence-transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "ST_MODEL_NAME = \"almanach/camembert-base\"\n",
    "st_model = SentenceTransformer(ST_MODEL_NAME)\n",
    "\n",
    "# Encodage des documents\n",
    "doc_vecs_st = st_model.encode(corpus, convert_to_numpy=True, normalize_embeddings=True)\n",
    "\n",
    "def search_st(query: str, top_k: int = 5):\n",
    "    q_vec = st_model.encode([query], convert_to_numpy=True, normalize_embeddings=True)[0]\n",
    "    scores = doc_vecs_st @ q_vec  # produit scalaire = cosinus car normalisé\n",
    "    ids = np.arange(len(corpus))\n",
    "    show_topk(query, ids, scores, k=top_k)\n",
    "\n",
    "for q in queries:\n",
    "    search_st(q, top_k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324981da",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Indexation avec **FAISS** \n",
    "\n",
    "Pour une grande collection, on utilise un index de recherche de voisins approchés (ANN).  \n",
    "**Astuce** : pour la **cosine**, normalisez les vecteurs et utilisez un index `IndexFlatIP` (produit interne). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6948111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index FAISS — nb vecteurs: 53\n",
      "\n",
      "Query: 'comment fonctionne BM25 (k1, b) pour le ranking ?'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9269  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 2] score=0.9213  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=0.9180  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 4] score=0.9060  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 5] score=0.9048  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "\n",
      "Query: 'différence entre sac de mots et TF-IDF'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9239  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 2] score=0.9192  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 3] score=0.9170  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 4] score=0.9109  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 5] score=0.9034  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "\n",
      "Query: 'CountVectorizer vs TfidfVectorizer scikit-learn'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9581  doc#16 → Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "[ 2] score=0.9300  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 3] score=0.9037  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 4] score=0.8915  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 5] score=0.8845  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "\n",
      "Query: 'bm25 ranking vs dense retrieval'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8900  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 2] score=0.8831  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 3] score=0.8793  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 4] score=0.8756  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 5] score=0.8751  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "\n",
      "Query: 'quels avantages des embeddings denses pour la sémantique ?'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9126  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 2] score=0.9114  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 3] score=0.9029  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 4] score=0.9024  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 5] score=0.8976  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "\n",
      "Query: 'liste de stopwords en français et impact sur la précision'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9003  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 2] score=0.8925  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 3] score=0.8913  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 4] score=0.8808  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 5] score=0.8797  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "\n",
      "Query: 'lemmatisation vs stemming pour le français'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8726  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 2] score=0.8513  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 3] score=0.8487  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 4] score=0.8350  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 5] score=0.8335  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "\n",
      "Query: 'normalisation des accents et diacritiques'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8469  doc#12 → La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "[ 2] score=0.8211  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 3] score=0.7964  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 4] score=0.7857  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 5] score=0.7788  doc#29 → Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "\n",
      "Query: \"gerer les fautes de frappe en recherche d'information\"\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8342  doc#0 → La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "[ 2] score=0.8212  doc#14 → Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 3] score=0.8175  doc#51 → En RAG, l'ordre : retrieve → read → generate ; la qualité du retrieve détermine souvent 80% du succès perçu.\n",
      "[ 4] score=0.8134  doc#12 → La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "[ 5] score=0.8108  doc#27 → Dans le domaine médical, la précision terminologique est cruciale (ex. 'hypertension artérielle').\n",
      "\n",
      "Query: 'traiter les hashtags et urls dans les documents'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8887  doc#26 → Les requêtes peuvent être multilingues ; les modèles multilingues mappent plusieurs langues dans le même espace.\n",
      "[ 2] score=0.8810  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 3] score=0.8714  doc#49 → Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\n",
      "[ 4] score=0.8707  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 5] score=0.8668  doc#33 → URLs et hashtags (#IR, #NLP) perturbent parfois la segmentation en tokens.\n",
      "\n",
      "Query: 'comparer MAP, MRR et nDCG@10'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9149  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 2] score=0.9102  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 3] score=0.8902  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 4] score=0.8868  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 5] score=0.8825  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "\n",
      "Query: \"datasets d'évaluation: TREC, MS MARCO, BEIR\"\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9271  doc#23 → Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 2] score=0.8983  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 3] score=0.8925  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 4] score=0.8920  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 5] score=0.8897  doc#18 → FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "\n",
      "Query: 'pooling et jugement de pertinence gradué'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9047  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 2] score=0.8997  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=0.8667  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 4] score=0.8658  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 5] score=0.8655  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "\n",
      "Query: 'quelle métrique pour la pertinence multi-niveaux ?'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8936  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 2] score=0.8884  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 3] score=0.8824  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 4] score=0.8810  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 5] score=0.8798  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "\n",
      "Query: 'recherche multilingue avec SBERT ou E5'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9004  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 2] score=0.8965  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 3] score=0.8909  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 4] score=0.8825  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 5] score=0.8740  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "\n",
      "Query: 'RAG pour questions médicales'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8552  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 2] score=0.8232  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 3] score=0.8157  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 4] score=0.7960  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 5] score=0.7911  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "\n",
      "Query: \"désambiguïser l'acronyme IR selon le contexte\"\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8617  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 2] score=0.8537  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 3] score=0.8501  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 4] score=0.8470  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 5] score=0.8469  doc#49 → Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\n",
      "\n",
      "Query: 'recherche juridique: articles et alinéas'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8948  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 2] score=0.8669  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 3] score=0.8631  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 4] score=0.8595  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 5] score=0.8417  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "\n",
      "Query: 'recettes: pondération TF simple vs BM25'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8767  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 2] score=0.8719  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 3] score=0.8689  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 4] score=0.8606  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 5] score=0.8450  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "\n",
      "Query: 'HNSW vs FAISS vs Annoy pour ANN'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8899  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 2] score=0.8859  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 3] score=0.8775  doc#18 → FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "[ 4] score=0.8672  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 5] score=0.8662  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "\n",
      "Query: 'hybrid search: combiner BM25 et embeddings'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9280  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 2] score=0.9055  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 3] score=0.8965  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 4] score=0.8954  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 5] score=0.8947  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "\n",
      "Query: 'cross-encoder pour reranking des top-k'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9233  doc#36 → Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "[ 2] score=0.9114  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 3] score=0.8995  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 4] score=0.8938  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 5] score=0.8864  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "\n",
      "Query: 'quantification des vecteurs (IVFPQ) et rappels'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9162  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 2] score=0.8954  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 3] score=0.8910  doc#23 → Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 4] score=0.8901  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 5] score=0.8886  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "\n",
      "Query: 'pondérer le champ title plus que body'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8925  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 2] score=0.8849  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 3] score=0.8818  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 4] score=0.8794  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 5] score=0.8759  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "\n",
      "Query: 'tf–idf (variante typographique) explication'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9127  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 2] score=0.9024  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 3] score=0.8991  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 4] score=0.8987  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 5] score=0.8954  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "\n",
      "Query: 'embeding denses (typo) utilité'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9070  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 2] score=0.9028  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 3] score=0.8980  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 4] score=0.8900  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 5] score=0.8851  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "\n",
      "Query: 'Okapi-BM25 formule'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8676  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 2] score=0.8619  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 3] score=0.8457  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 4] score=0.8394  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 5] score=0.8221  doc#16 → Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "\n",
      "Query: 'vector search sparse or dense'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8926  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 2] score=0.8869  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 3] score=0.8630  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 4] score=0.8593  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 5] score=0.8533  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "\n",
      "Query: 'BM25 sans normalisation de longueur'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9022  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 2] score=0.8960  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=0.8801  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 4] score=0.8768  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 5] score=0.8668  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %pip -q install faiss-cpu\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dim = doc_vecs_st.shape[1]\n",
    "index = faiss.IndexFlatIP(dim)  # alternative IndexFlatL2\n",
    "index.add(doc_vecs_st.astype(np.float32))\n",
    "print(\"Index FAISS — nb vecteurs:\", index.ntotal)\n",
    "\n",
    "def faiss_search(query: str, top_k: int = 5):\n",
    "    q = st_model.encode([query], convert_to_numpy=True, normalize_embeddings=True).astype(np.float32)\n",
    "    scores, ids = index.search(q, top_k)  #\n",
    "    print(f\"\\nQuery: {query!r}\")\n",
    "    print(\"-\" * 80)\n",
    "    for r, (s, i) in enumerate(zip(scores[0], ids[0]), start=1):\n",
    "        print(f\"[{r:>2}] score={float(s):.4f}  doc#{int(i)} → {corpus[int(i)]}\")\n",
    "\n",
    "# Démo\n",
    "for q in queries:\n",
    "    faiss_search(q, top_k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938b35b4",
   "metadata": {},
   "source": [
    "\n",
    "## 3) **Re-ranking** avec un **Cross-Encoder** (HF)\n",
    "\n",
    "Les embeddings donnent un **premier tri rapide**. Pour un meilleur ordre final, on ré-évalue les **Top-N** candidats\n",
    "avec un **Cross-Encoder** (un modèle qui lit *la paire* `(requête, document)` et prédit un score de pertinence).\n",
    "\n",
    "Exemple : `cross-encoder/ms-marco-MiniLM-L-6-v2` (principalement entraîné en anglais, mais fonctionne souvent raisonnablement en FR).  \n",
    "Pour du 100% FR, choisir un reranker multilingue quand c'est possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9befde69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: 'comment fonctionne BM25 (k1, b) pour le ranking ?'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.9978  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 2] CE_score=0.9968  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 3] CE_score=0.9649  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 4] CE_score=0.8686  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 5] CE_score=0.0550  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "\n",
      "Query: 'différence entre sac de mots et TF-IDF'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.8537  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 2] CE_score=0.6334  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 3] CE_score=0.0049  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 4] CE_score=0.0034  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 5] CE_score=0.0028  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "\n",
      "Query: 'CountVectorizer vs TfidfVectorizer scikit-learn'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.9988  doc#16 → Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "[ 2] CE_score=0.0082  doc#36 → Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "[ 3] CE_score=0.0077  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 4] CE_score=0.0056  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 5] CE_score=0.0055  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "\n",
      "Query: 'bm25 ranking vs dense retrieval'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.8926  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 2] CE_score=0.1736  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 3] CE_score=0.0838  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 4] CE_score=0.0244  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 5] CE_score=0.0090  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "\n",
      "Query: 'quels avantages des embeddings denses pour la sémantique ?'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.6650  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 2] CE_score=0.2050  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 3] CE_score=0.0298  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 4] CE_score=0.0125  doc#29 → Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "[ 5] CE_score=0.0102  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "\n",
      "Query: 'liste de stopwords en français et impact sur la précision'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.2023  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 2] CE_score=0.0767  doc#40 → Le sac de mots (bag of words) est simple et robuste mais ne capture pas la sémantique profonde.\n",
      "[ 3] CE_score=0.0669  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 4] CE_score=0.0081  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 5] CE_score=0.0058  doc#49 → Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\n",
      "\n",
      "Query: 'lemmatisation vs stemming pour le français'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.1807  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 2] CE_score=0.0145  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 3] CE_score=0.0059  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 4] CE_score=0.0050  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 5] CE_score=0.0034  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "\n",
      "Query: 'normalisation des accents et diacritiques'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.9407  doc#50 → La normalisation Unicode (NFC/NFKD) affecte le traitement des diacritiques (é/ê/e).\n",
      "[ 2] CE_score=0.1089  doc#12 → La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "[ 3] CE_score=0.0606  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 4] CE_score=0.0313  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 5] CE_score=0.0084  doc#49 → Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\n",
      "\n",
      "Query: \"gerer les fautes de frappe en recherche d'information\"  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.8093  doc#14 → Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 2] CE_score=0.0080  doc#51 → En RAG, l'ordre : retrieve → read → generate ; la qualité du retrieve détermine souvent 80% du succès perçu.\n",
      "[ 3] CE_score=0.0042  doc#38 → Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "[ 4] CE_score=0.0023  doc#49 → Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\n",
      "[ 5] CE_score=0.0021  doc#0 → La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "\n",
      "Query: 'traiter les hashtags et urls dans les documents'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.1258  doc#33 → URLs et hashtags (#IR, #NLP) perturbent parfois la segmentation en tokens.\n",
      "[ 2] CE_score=0.0577  doc#49 → Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\n",
      "[ 3] CE_score=0.0502  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 4] CE_score=0.0287  doc#26 → Les requêtes peuvent être multilingues ; les modèles multilingues mappent plusieurs langues dans le même espace.\n",
      "[ 5] CE_score=0.0250  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "\n",
      "Query: 'comparer MAP, MRR et nDCG@10'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.9393  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 2] CE_score=0.0033  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 3] CE_score=0.0032  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 4] CE_score=0.0022  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 5] CE_score=0.0016  doc#16 → Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "\n",
      "Query: \"datasets d'évaluation: TREC, MS MARCO, BEIR\"  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.9939  doc#23 → Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 2] CE_score=0.0276  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 3] CE_score=0.0069  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 4] CE_score=0.0030  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 5] CE_score=0.0029  doc#18 → FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "\n",
      "Query: 'pooling et jugement de pertinence gradué'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.4841  doc#25 → Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "[ 2] CE_score=0.0331  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 3] CE_score=0.0122  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 4] CE_score=0.0039  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 5] CE_score=0.0021  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "\n",
      "Query: 'quelle métrique pour la pertinence multi-niveaux ?'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.2477  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 2] CE_score=0.0140  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] CE_score=0.0111  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 4] CE_score=0.0055  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 5] CE_score=0.0042  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "\n",
      "Query: 'recherche multilingue avec SBERT ou E5'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.1329  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 2] CE_score=0.0094  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 3] CE_score=0.0026  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 4] CE_score=0.0021  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 5] CE_score=0.0017  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "\n",
      "Query: 'RAG pour questions médicales'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.2836  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 2] CE_score=0.0220  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] CE_score=0.0201  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 4] CE_score=0.0096  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 5] CE_score=0.0042  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "\n",
      "Query: \"désambiguïser l'acronyme IR selon le contexte\"  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.0364  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 2] CE_score=0.0321  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 3] CE_score=0.0261  doc#49 → Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\n",
      "[ 4] CE_score=0.0224  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 5] CE_score=0.0068  doc#23 → Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "\n",
      "Query: 'recherche juridique: articles et alinéas'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.0396  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 2] CE_score=0.0182  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 3] CE_score=0.0062  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 4] CE_score=0.0033  doc#29 → Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "[ 5] CE_score=0.0032  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "\n",
      "Query: 'recettes: pondération TF simple vs BM25'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.6102  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 2] CE_score=0.0310  doc#29 → Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "[ 3] CE_score=0.0089  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 4] CE_score=0.0066  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 5] CE_score=0.0043  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "\n",
      "Query: 'HNSW vs FAISS vs Annoy pour ANN'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.9978  doc#18 → FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "[ 2] CE_score=0.0194  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 3] CE_score=0.0063  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 4] CE_score=0.0059  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 5] CE_score=0.0046  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "\n",
      "Query: 'hybrid search: combiner BM25 et embeddings'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.8160  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 2] CE_score=0.0821  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 3] CE_score=0.0440  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 4] CE_score=0.0129  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 5] CE_score=0.0065  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "\n",
      "Query: 'cross-encoder pour reranking des top-k'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.9989  doc#36 → Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "[ 2] CE_score=0.0054  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] CE_score=0.0023  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 4] CE_score=0.0019  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 5] CE_score=0.0013  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "\n",
      "Query: 'quantification des vecteurs (IVFPQ) et rappels'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.0196  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 2] CE_score=0.0164  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 3] CE_score=0.0076  doc#23 → Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 4] CE_score=0.0064  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 5] CE_score=0.0035  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "\n",
      "Query: 'pondérer le champ title plus que body'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.0568  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 2] CE_score=0.0459  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 3] CE_score=0.0140  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 4] CE_score=0.0123  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 5] CE_score=0.0066  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "\n",
      "Query: 'tf–idf (variante typographique) explication'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.6548  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 2] CE_score=0.0223  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 3] CE_score=0.0148  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 4] CE_score=0.0070  doc#36 → Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "[ 5] CE_score=0.0058  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "\n",
      "Query: 'embeding denses (typo) utilité'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.0642  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 2] CE_score=0.0221  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 3] CE_score=0.0066  doc#16 → Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "[ 4] CE_score=0.0026  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 5] CE_score=0.0024  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "\n",
      "Query: 'Okapi-BM25 formule'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.9989  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 2] CE_score=0.0053  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 3] CE_score=0.0023  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 4] CE_score=0.0016  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 5] CE_score=0.0013  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "\n",
      "Query: 'vector search sparse or dense'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.9986  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 2] CE_score=0.2670  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 3] CE_score=0.0319  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 4] CE_score=0.0095  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 5] CE_score=0.0079  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "\n",
      "Query: 'BM25 sans normalisation de longueur'  —  Re-ranking sur 8 candidats\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] CE_score=0.9988  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 2] CE_score=0.9949  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] CE_score=0.9172  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 4] CE_score=0.6320  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 5] CE_score=0.0542  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %pip -q install sentence-transformers\n",
    "\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# Reranker (vous pouvez choisir un autre modèle HF)\n",
    "CE_MODEL_NAME = \"antoinelouis/crossencoder-camembert-base-mmarcoFR\"\n",
    "reranker = CrossEncoder(CE_MODEL_NAME)\n",
    "\n",
    "def rerank_with_cross_encoder(query: str, top_n_from_dense: int = 8, final_k: int = 5):\n",
    "    # 1) Récupération dense (FAISS) pour réduire la recherche\n",
    "    q = st_model.encode([query], convert_to_numpy=True, normalize_embeddings=True).astype(np.float32)\n",
    "    scores, ids = index.search(q, top_n_from_dense)\n",
    "    candidate_ids = ids[0].tolist()\n",
    "\n",
    "    # 2) Paires (query, passage) pour le CrossEncoder\n",
    "    pairs = [(query, corpus[i]) for i in candidate_ids]\n",
    "    ce_scores = reranker.predict(pairs)  # plus lent mais plus précis\n",
    "    order = np.argsort(-ce_scores)[:final_k]\n",
    "\n",
    "    print(f\"\\nQuery: {query!r}  —  Re-ranking sur {top_n_from_dense} candidats\")\n",
    "    print(\"-\" * 80)\n",
    "    for r, j in enumerate(order, start=1):\n",
    "        i = candidate_ids[j]\n",
    "        print(f\"[{r:>2}] CE_score={float(ce_scores[j]):.4f}  doc#{i} → {corpus[i]}\")\n",
    "\n",
    "# Démo\n",
    "for q in queries:\n",
    "    rerank_with_cross_encoder(q, top_n_from_dense=8, final_k=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
