{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b930c62",
   "metadata": {},
   "source": [
    "\n",
    "# Sparse Vector Retrieval (Récupération par vecteurs creux)\n",
    "\n",
    "Ce notebook est un **exemple pédagogique** pour introduire la récupération d'information (IR) avec des représentations **sparse** (creuses).  \n",
    "On explore trois approches classiques :\n",
    "\n",
    "1. **Bag of Words / CountVectorizer** — fréquence brute des mots (sac de mots).  \n",
    "2. **TF‑IDF (Term Frequency – Inverse Document Frequency)** — pondère les termes fréquents dans un document mais rares dans la collection.  \n",
    "3. **BM25** — une famille de scores probabilistes très utilisée dans les moteurs de recherche.  \n",
    "\n",
    "Chaque sous‑section inclut : une **explication** + un **exemple de code** pour indexer une mini‑collection et retrouver les documents les plus pertinents pour une requête.\n",
    "\n",
    "> *Note « Hugging Face » : dans cette section « sparse », nous n'avons pas besoin de modèles HF. Les parties denses (Section 2) tireront parti d'`transformers`/`sentence-transformers`. Ici, on se concentre sur les méthodes classiques ne nécessitant pas de réseau de neurones.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6e7176",
   "metadata": {},
   "source": [
    "\n",
    "## Préparation\n",
    "On définit une petite collection de documents (un mini‑corpus) pour l'exercice et quelques requêtes.  \n",
    "On utilisera **scikit‑learn** pour *CountVectorizer* et *TfidfVectorizer*, et une **implémentation BM25 maison** pour éviter toute dépendance externe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54b3d7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 53  |  Requêtes: ['comment fonctionne BM25 (k1, b) pour le ranking ?', 'différence entre sac de mots et TF-IDF', 'CountVectorizer vs TfidfVectorizer scikit-learn', 'bm25 ranking vs dense retrieval', 'quels avantages des embeddings denses pour la sémantique ?', 'liste de stopwords en français et impact sur la précision', 'lemmatisation vs stemming pour le français', 'normalisation des accents et diacritiques', \"gerer les fautes de frappe en recherche d'information\", 'traiter les hashtags et urls dans les documents', 'comparer MAP, MRR et nDCG@10', \"datasets d'évaluation: TREC, MS MARCO, BEIR\", 'pooling et jugement de pertinence gradué', 'quelle métrique pour la pertinence multi-niveaux ?', 'recherche multilingue avec SBERT ou E5', 'RAG pour questions médicales', \"désambiguïser l'acronyme IR selon le contexte\", 'recherche juridique: articles et alinéas', 'recettes: pondération TF simple vs BM25', 'HNSW vs FAISS vs Annoy pour ANN', 'hybrid search: combiner BM25 et embeddings', 'cross-encoder pour reranking des top-k', 'quantification des vecteurs (IVFPQ) et rappels', 'pondérer le champ title plus que body', 'tf–idf (variante typographique) explication', 'embeding denses (typo) utilité', 'Okapi-BM25 formule', 'vector search sparse or dense', 'BM25 sans normalisation de longueur']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Imports de base\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Un mini-corpus jouet (FR + un peu d'EN pour montrer la robustesse)\n",
    "corpus = [\n",
    "    # --- Concepts généraux & définitions ---\n",
    "    \"La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\",\n",
    "    \"Un pipeline RI comporte souvent : prétraitement, indexation, pondération, scoring, puis évaluation des résultats.\",\n",
    "    \"Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\",\n",
    "    \"TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\",\n",
    "    \"Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\",\n",
    "    \"BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\",\n",
    "    \"Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\",\n",
    "    \"La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\",\n",
    "    \"RAG (Retrieval-Augmented Generation) combine récupération de passages et modèles génératifs pour produire des réponses sourcées.\",\n",
    "    \"La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\",\n",
    "\n",
    "    # --- Prétraitement & normalisation ---\n",
    "    \"La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\",\n",
    "    \"Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\",\n",
    "    \"La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\",\n",
    "    \"Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\",\n",
    "    \"Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\",\n",
    "    \"Les entités nommées (NER) aident à conserver des unités sémantiques comme 'OpenAI' ou 'Europe/Paris'.\",\n",
    "\n",
    "    # --- Outils & bibliothèques ---\n",
    "    \"Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\",\n",
    "    \"Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\",\n",
    "    \"FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\",\n",
    "    \"Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\",\n",
    "    \"Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\",\n",
    "\n",
    "    # --- Évaluation ---\n",
    "    \"L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\",\n",
    "    \"MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\",\n",
    "    \"Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\",\n",
    "    \"La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\",\n",
    "    \"Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\",\n",
    "\n",
    "    # --- Multilingue & domaines ---\n",
    "    \"Les requêtes peuvent être multilingues ; les modèles multilingues mappent plusieurs langues dans le même espace.\",\n",
    "    \"Dans le domaine médical, la précision terminologique est cruciale (ex. 'hypertension artérielle').\",\n",
    "    \"En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\",\n",
    "    \"Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\",\n",
    "    \"La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\",\n",
    "\n",
    "    # --- Bruit, longueur et structure ---\n",
    "    \"Certains documents sont très courts: 'BM25 expliqué rapidement'.\",\n",
    "    \"D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\",\n",
    "    \"URLs et hashtags (#IR, #NLP) perturbent parfois la segmentation en tokens.\",\n",
    "    \"Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\",\n",
    "\n",
    "    # --- Recherche hybride & reranking ---\n",
    "    \"La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\",\n",
    "    \"Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\",\n",
    "    \"La réduction de dimension (PCA) ou la quantification des vecteurs (PQ, IVFPQ) accélère l'ANN au prix d'une légère perte de rappel.\",\n",
    "    \"Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\",\n",
    "    \"La désambiguïsation des acronymes (ex. 'IR' = 'information retrieval' ou 'imagerie par résonance') dépend du contexte.\",\n",
    "\n",
    "    # --- Cas concrets & exemples mixtes ---\n",
    "    \"Le sac de mots (bag of words) est simple et robuste mais ne capture pas la sémantique profonde.\",\n",
    "    \"TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\",\n",
    "    \"Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\",\n",
    "    \"Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\",\n",
    "    \"La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\",\n",
    "    \"Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\",\n",
    "    \"L'alignement d'espaces multilingues permet 'apprentissage' ≈ 'learning' ≈ 'aprendizaje'.\",\n",
    "    \"Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\",\n",
    "    \"Le choix des stop words en français diffère de l'anglais (ex. 'au', 'aux', 'des', 'du').\",\n",
    "    \"Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\",\n",
    "    \"La normalisation Unicode (NFC/NFKD) affecte le traitement des diacritiques (é/ê/e).\",\n",
    "    \"En RAG, l'ordre : retrieve → read → generate ; la qualité du retrieve détermine souvent 80% du succès perçu.\",\n",
    "    \"Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\"\n",
    "]\n",
    "\n",
    "queries = [\n",
    "    # Requêtes ciblées IR\n",
    "    \"comment fonctionne BM25 (k1, b) pour le ranking ?\",\n",
    "    \"différence entre sac de mots et TF-IDF\",\n",
    "    \"CountVectorizer vs TfidfVectorizer scikit-learn\",\n",
    "    \"bm25 ranking vs dense retrieval\",\n",
    "    \"quels avantages des embeddings denses pour la sémantique ?\",\n",
    "\n",
    "    # Prétraitement & robustesse\n",
    "    \"liste de stopwords en français et impact sur la précision\",\n",
    "    \"lemmatisation vs stemming pour le français\",\n",
    "    \"normalisation des accents et diacritiques\",\n",
    "    \"gerer les fautes de frappe en recherche d'information\",\n",
    "    \"traiter les hashtags et urls dans les documents\",\n",
    "\n",
    "    # Évaluation\n",
    "    \"comparer MAP, MRR et nDCG@10\",\n",
    "    \"datasets d'évaluation: TREC, MS MARCO, BEIR\",\n",
    "    \"pooling et jugement de pertinence gradué\",\n",
    "    \"quelle métrique pour la pertinence multi-niveaux ?\",\n",
    "\n",
    "    # Multilingue & domaines\n",
    "    \"recherche multilingue avec SBERT ou E5\",\n",
    "    \"RAG pour questions médicales\",\n",
    "    \"désambiguïser l'acronyme IR selon le contexte\",\n",
    "    \"recherche juridique: articles et alinéas\",\n",
    "    \"recettes: pondération TF simple vs BM25\",\n",
    "\n",
    "    # ANN & systèmes\n",
    "    \"HNSW vs FAISS vs Annoy pour ANN\",\n",
    "    \"hybrid search: combiner BM25 et embeddings\",\n",
    "    \"cross-encoder pour reranking des top-k\",\n",
    "    \"quantification des vecteurs (IVFPQ) et rappels\",\n",
    "    \"pondérer le champ title plus que body\",\n",
    "\n",
    "    # Requêtes bruitées / mixtes / typos\n",
    "    \"tf–idf (variante typographique) explication\",\n",
    "    \"embeding denses (typo) utilité\",\n",
    "    \"Okapi-BM25 formule\",\n",
    "    \"vector search sparse or dense\",\n",
    "    \"BM25 sans normalisation de longueur\"\n",
    "]\n",
    "print(f\"Documents: {len(corpus)}  |  Requêtes: {queries}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade2f41b",
   "metadata": {},
   "source": [
    "\n",
    "### Fonction utilitaire d'affichage\n",
    "Une petite fonction pour afficher les **Top‑k** documents retournés par chaque méthode avec leur score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa501b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_results(query: str, doc_ids: List[int], scores: np.ndarray, top_k: int = 5):\n",
    "    print(f\"\\nQuery: {query!r}\")\n",
    "    print(\"-\" * 80)\n",
    "    idx_sorted = np.argsort(scores)[::-1][:top_k]\n",
    "    for rank, i in enumerate(idx_sorted, start=1):\n",
    "        print(f\"[{rank:>2}] score={scores[i]:.4f}  doc#{doc_ids[i]}  →  {corpus[doc_ids[i]]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ef4eb3",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Bag of Words / **CountVectorizer**\n",
    "\n",
    "**Idée** : représenter chaque document par un vecteur de **comptes** de mots, sans tenir compte de l'ordre (modèle du **sac de mots**).  \n",
    "- Avantages : simple, rapide, robuste sur de petits corpus.  \n",
    "- Limites : pas de pondération par rareté, insensible aux synonymes et au contexte.\n",
    "\n",
    "**Pipeline** :\n",
    "1. *Tokenisation* + vocabulaire (par `CountVectorizer`).  \n",
    "2. Encodage des documents et de la requête.  \n",
    "3. Calcul de similarité (cosinus) puis tri décroissant des scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f23cbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: 'comment fonctionne BM25 (k1, b) pour le ranking ?'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3254  doc#11  →  Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 2] score=0.3254  doc#42  →  Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 3] score=0.3078  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 4] score=0.2860  doc#47  →  Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 5] score=0.2860  doc#24  →  La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "\n",
      "Query: 'différence entre sac de mots et TF-IDF'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.4352  doc#2  →  Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 2] score=0.3849  doc#40  →  Le sac de mots (bag of words) est simple et robuste mais ne capture pas la sémantique profonde.\n",
      "[ 3] score=0.3397  doc#17  →  Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 4] score=0.3203  doc#41  →  TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 5] score=0.3143  doc#3  →  TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "\n",
      "Query: 'CountVectorizer vs TfidfVectorizer scikit-learn'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6325  doc#16  →  Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "[ 2] score=0.1179  doc#34  →  Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 3] score=0.0000  doc#52  →  Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "[ 4] score=0.0000  doc#13  →  Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "[ 5] score=0.0000  doc#23  →  Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "\n",
      "Query: 'bm25 ranking vs dense retrieval'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3638  doc#42  →  Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 2] score=0.2500  doc#20  →  Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 3] score=0.1890  doc#4  →  Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 4] score=0.1768  doc#31  →  Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 5] score=0.1387  doc#43  →  Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "\n",
      "Query: 'quels avantages des embeddings denses pour la sémantique ?'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6556  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 2] score=0.5103  doc#6  →  Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "[ 3] score=0.4454  doc#44  →  La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 4] score=0.3608  doc#32  →  D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "[ 5] score=0.3203  doc#10  →  La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "\n",
      "Query: 'liste de stopwords en français et impact sur la précision'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.4677  doc#4  →  Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 2] score=0.3780  doc#28  →  En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "[ 3] score=0.3769  doc#47  →  Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 4] score=0.3467  doc#10  →  La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "[ 5] score=0.3430  doc#42  →  Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "\n",
      "Query: 'lemmatisation vs stemming pour le français'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3254  doc#11  →  Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 2] score=0.2860  doc#24  →  La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "[ 3] score=0.2631  doc#10  →  La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "[ 4] score=0.2390  doc#13  →  Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "[ 5] score=0.2236  doc#6  →  Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "\n",
      "Query: 'normalisation des accents et diacritiques'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.4880  doc#5  →  BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 2] score=0.4743  doc#32  →  D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "[ 3] score=0.4243  doc#50  →  La normalisation Unicode (NFC/NFKD) affecte le traitement des diacritiques (é/ê/e).\n",
      "[ 4] score=0.2860  doc#2  →  Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 5] score=0.2631  doc#10  →  La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "\n",
      "Query: \"gerer les fautes de frappe en recherche d'information\"\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5669  doc#14  →  Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 2] score=0.3780  doc#38  →  Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "[ 3] score=0.3299  doc#44  →  La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 4] score=0.3030  doc#28  →  En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "[ 5] score=0.2928  doc#12  →  La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "\n",
      "Query: 'traiter les hashtags et urls dans les documents'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.4303  doc#12  →  La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "[ 2] score=0.4167  doc#14  →  Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 3] score=0.3824  doc#26  →  Les requêtes peuvent être multilingues ; les modèles multilingues mappent plusieurs langues dans le même espace.\n",
      "[ 4] score=0.3162  doc#16  →  Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "[ 5] score=0.3015  doc#33  →  URLs et hashtags (#IR, #NLP) perturbent parfois la segmentation en tokens.\n",
      "\n",
      "Query: 'comparer MAP, MRR et nDCG@10'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5345  doc#21  →  L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 2] score=0.2500  doc#20  →  Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 3] score=0.2425  doc#22  →  MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "[ 4] score=0.2182  doc#5  →  BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 5] score=0.1768  doc#32  →  D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "\n",
      "Query: \"datasets d'évaluation: TREC, MS MARCO, BEIR\"\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.4781  doc#23  →  Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 2] score=0.1240  doc#1  →  Un pipeline RI comporte souvent : prétraitement, indexation, pondération, scoring, puis évaluation des résultats.\n",
      "[ 3] score=0.1195  doc#21  →  L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 4] score=0.0953  doc#24  →  La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "[ 5] score=0.0000  doc#13  →  Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "\n",
      "Query: 'pooling et jugement de pertinence gradué'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.4781  doc#25  →  Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "[ 2] score=0.3381  doc#4  →  Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=0.3254  doc#42  →  Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 4] score=0.2928  doc#5  →  BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 5] score=0.2860  doc#47  →  Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "\n",
      "Query: 'quelle métrique pour la pertinence multi-niveaux ?'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.4472  doc#9  →  La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "[ 2] score=0.4104  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 3] score=0.3508  doc#10  →  La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "[ 4] score=0.2390  doc#30  →  La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\n",
      "[ 5] score=0.2390  doc#25  →  Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "\n",
      "Query: 'recherche multilingue avec SBERT ou E5'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3464  doc#19  →  Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 2] score=0.2390  doc#30  →  La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\n",
      "[ 3] score=0.2390  doc#7  →  La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 4] score=0.1754  doc#41  →  TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 5] score=0.1291  doc#49  →  Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\n",
      "\n",
      "Query: 'RAG pour questions médicales'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3536  doc#8  →  RAG (Retrieval-Augmented Generation) combine récupération de passages et modèles génératifs pour produire des réponses sourcées.\n",
      "[ 2] score=0.3244  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 3] score=0.2236  doc#16  →  Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "[ 4] score=0.1826  doc#19  →  Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 5] score=0.1768  doc#6  →  Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "\n",
      "Query: \"désambiguïser l'acronyme IR selon le contexte\"\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3198  doc#24  →  La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "[ 2] score=0.2582  doc#39  →  La désambiguïsation des acronymes (ex. 'IR' = 'information retrieval' ou 'imagerie par résonance') dépend du contexte.\n",
      "[ 3] score=0.2425  doc#11  →  Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 4] score=0.1581  doc#50  →  La normalisation Unicode (NFC/NFKD) affecte le traitement des diacritiques (é/ê/e).\n",
      "[ 5] score=0.1508  doc#33  →  URLs et hashtags (#IR, #NLP) perturbent parfois la segmentation en tokens.\n",
      "\n",
      "Query: 'recherche juridique: articles et alinéas'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.4009  doc#28  →  En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "[ 2] score=0.3750  doc#20  →  Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 3] score=0.2582  doc#18  →  FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "[ 4] score=0.2500  doc#14  →  Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 5] score=0.2294  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "\n",
      "Query: 'recettes: pondération TF simple vs BM25'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.4781  doc#29  →  Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "[ 2] score=0.2169  doc#42  →  Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 3] score=0.1754  doc#41  →  TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 4] score=0.1721  doc#3  →  TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 5] score=0.1581  doc#31  →  Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "\n",
      "Query: 'HNSW vs FAISS vs Annoy pour ANN'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.4619  doc#18  →  FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "[ 2] score=0.2052  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 3] score=0.1414  doc#16  →  Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "[ 4] score=0.1155  doc#19  →  Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 5] score=0.1118  doc#6  →  Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "\n",
      "Query: 'hybrid search: combiner BM25 et embeddings'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3750  doc#20  →  Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 2] score=0.3638  doc#42  →  Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 3] score=0.3441  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 4] score=0.3273  doc#5  →  BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 5] score=0.2132  doc#47  →  Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "\n",
      "Query: 'cross-encoder pour reranking des top-k'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5620  doc#36  →  Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "[ 2] score=0.2887  doc#32  →  D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "[ 3] score=0.2041  doc#8  →  RAG (Retrieval-Augmented Generation) combine récupération de passages et modèles génératifs pour produire des réponses sourcées.\n",
      "[ 4] score=0.1980  doc#48  →  Le choix des stop words en français diffère de l'anglais (ex. 'au', 'aux', 'des', 'du').\n",
      "[ 5] score=0.1925  doc#0  →  La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "\n",
      "Query: 'quantification des vecteurs (IVFPQ) et rappels'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.4743  doc#32  →  D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "[ 2] score=0.3904  doc#5  →  BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 3] score=0.3578  doc#37  →  La réduction de dimension (PCA) ou la quantification des vecteurs (PQ, IVFPQ) accélère l'ANN au prix d'une légère perte de rappel.\n",
      "[ 4] score=0.2860  doc#2  →  Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 5] score=0.2481  doc#17  →  Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "\n",
      "Query: 'pondérer le champ title plus que body'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6124  doc#38  →  Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "[ 2] score=0.2611  doc#24  →  La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "[ 3] score=0.1980  doc#11  →  Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 4] score=0.1291  doc#50  →  La normalisation Unicode (NFC/NFKD) affecte le traitement des diacritiques (é/ê/e).\n",
      "[ 5] score=0.1179  doc#49  →  Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\n",
      "\n",
      "Query: 'tf–idf (variante typographique) explication'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5547  doc#41  →  TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 2] score=0.4082  doc#3  →  TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 3] score=0.3922  doc#17  →  Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 4] score=0.1890  doc#29  →  Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "[ 5] score=0.0000  doc#52  →  Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "\n",
      "Query: 'embeding denses (typo) utilité'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6172  doc#44  →  La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 2] score=0.1768  doc#6  →  Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "[ 3] score=0.1622  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 4] score=0.0000  doc#52  →  Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "[ 5] score=0.0000  doc#13  →  Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "\n",
      "Query: 'Okapi-BM25 formule'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5145  doc#42  →  Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 2] score=0.2673  doc#4  →  Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=0.2500  doc#31  →  Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 4] score=0.1961  doc#43  →  Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 5] score=0.1768  doc#20  →  Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "\n",
      "Query: 'vector search sparse or dense'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5976  doc#45  →  Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 2] score=0.2390  doc#7  →  La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 3] score=0.2236  doc#20  →  Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 4] score=0.1155  doc#19  →  Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 5] score=0.0000  doc#52  →  Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "\n",
      "Query: 'BM25 sans normalisation de longueur'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6202  doc#43  →  Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 2] score=0.5071  doc#4  →  Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=0.4767  doc#47  →  Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 4] score=0.4339  doc#42  →  Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 5] score=0.3904  doc#5  →  BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Vectorisation BoW\n",
    "count_vec = CountVectorizer(lowercase=True, stop_words=None)  # on garde simple\n",
    "X_count = count_vec.fit_transform(corpus)\n",
    "\n",
    "# Encodage d'une requête → même espace vectoriel\n",
    "def bow_search(query: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    q_vec = count_vec.transform([query])\n",
    "    # Similarité cosinus entre la requête et chaque document\n",
    "    scores = cosine_similarity(q_vec, X_count).ravel()\n",
    "    doc_ids = np.arange(X_count.shape[0])\n",
    "    return doc_ids, scores\n",
    "\n",
    "# Démo sur quelques requêtes\n",
    "for q in queries:\n",
    "    ids, sc = bow_search(q)\n",
    "    show_results(q, ids, sc, top_k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5b15c8",
   "metadata": {},
   "source": [
    "\n",
    "## 2) **TF‑IDF** **(term frequency-inverse document frequency)**\n",
    "\n",
    "**Idée** : pondérer les termes par la fréquence dans le document (**TF**) et la rareté dans la collection (**IDF**).  \n",
    "Ainsi, un terme très courant dans tous les documents aura un poids plus faible qu'un terme rare.\n",
    "\n",
    "\n",
    "On réutilise la similarité cosinus pour le ranking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d9d8c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: 'comment fonctionne BM25 (k1, b) pour le ranking ?'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.4227  doc#47  →  Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 2] score=0.3281  doc#42  →  Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 3] score=0.2362  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 4] score=0.2105  doc#4  →  Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 5] score=0.1755  doc#11  →  Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "\n",
      "Query: 'différence entre sac de mots et TF-IDF'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3752  doc#2  →  Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 2] score=0.3405  doc#41  →  TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 3] score=0.3350  doc#3  →  TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 4] score=0.2734  doc#17  →  Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 5] score=0.2729  doc#40  →  Le sac de mots (bag of words) est simple et robuste mais ne capture pas la sémantique profonde.\n",
      "\n",
      "Query: 'CountVectorizer vs TfidfVectorizer scikit-learn'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.7073  doc#16  →  Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "[ 2] score=0.1090  doc#34  →  Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 3] score=0.0000  doc#52  →  Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "[ 4] score=0.0000  doc#13  →  Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "[ 5] score=0.0000  doc#23  →  Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "\n",
      "Query: 'bm25 ranking vs dense retrieval'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3414  doc#42  →  Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 2] score=0.2191  doc#4  →  Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=0.2083  doc#20  →  Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 4] score=0.1529  doc#39  →  La désambiguïsation des acronymes (ex. 'IR' = 'information retrieval' ou 'imagerie par résonance') dépend du contexte.\n",
      "[ 5] score=0.1442  doc#8  →  RAG (Retrieval-Augmented Generation) combine récupération de passages et modèles génératifs pour produire des réponses sourcées.\n",
      "\n",
      "Query: 'quels avantages des embeddings denses pour la sémantique ?'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6009  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 2] score=0.4884  doc#6  →  Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "[ 3] score=0.4705  doc#44  →  La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 4] score=0.1556  doc#32  →  D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "[ 5] score=0.1365  doc#40  →  Le sac de mots (bag of words) est simple et robuste mais ne capture pas la sémantique profonde.\n",
      "\n",
      "Query: 'liste de stopwords en français et impact sur la précision'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.2444  doc#48  →  Le choix des stop words en français diffère de l'anglais (ex. 'au', 'aux', 'des', 'du').\n",
      "[ 2] score=0.2271  doc#4  →  Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=0.1965  doc#11  →  Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 4] score=0.1654  doc#21  →  L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 5] score=0.1474  doc#27  →  Dans le domaine médical, la précision terminologique est cruciale (ex. 'hypertension artérielle').\n",
      "\n",
      "Query: 'lemmatisation vs stemming pour le français'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3525  doc#10  →  La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "[ 2] score=0.2109  doc#48  →  Le choix des stop words en français diffère de l'anglais (ex. 'au', 'aux', 'des', 'du').\n",
      "[ 3] score=0.1861  doc#13  →  Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "[ 4] score=0.1646  doc#11  →  Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 5] score=0.1509  doc#12  →  La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "\n",
      "Query: 'normalisation des accents et diacritiques'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3842  doc#50  →  La normalisation Unicode (NFC/NFKD) affecte le traitement des diacritiques (é/ê/e).\n",
      "[ 2] score=0.3365  doc#10  →  La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "[ 3] score=0.2360  doc#5  →  BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 4] score=0.1911  doc#32  →  D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "[ 5] score=0.1430  doc#43  →  Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "\n",
      "Query: \"gerer les fautes de frappe en recherche d'information\"\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.4482  doc#14  →  Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 2] score=0.2121  doc#44  →  La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 3] score=0.1874  doc#0  →  La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "[ 4] score=0.1450  doc#28  →  En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "[ 5] score=0.1448  doc#38  →  Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "\n",
      "Query: 'traiter les hashtags et urls dans les documents'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3543  doc#33  →  URLs et hashtags (#IR, #NLP) perturbent parfois la segmentation en tokens.\n",
      "[ 2] score=0.1892  doc#26  →  Les requêtes peuvent être multilingues ; les modèles multilingues mappent plusieurs langues dans le même espace.\n",
      "[ 3] score=0.1710  doc#3  →  TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 4] score=0.1653  doc#12  →  La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "[ 5] score=0.1588  doc#14  →  Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "\n",
      "Query: 'comparer MAP, MRR et nDCG@10'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5219  doc#21  →  L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 2] score=0.2653  doc#22  →  MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "[ 3] score=0.0694  doc#20  →  Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 4] score=0.0660  doc#5  →  BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 5] score=0.0566  doc#32  →  D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "\n",
      "Query: \"datasets d'évaluation: TREC, MS MARCO, BEIR\"\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5771  doc#23  →  Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 2] score=0.1027  doc#1  →  Un pipeline RI comporte souvent : prétraitement, indexation, pondération, scoring, puis évaluation des résultats.\n",
      "[ 3] score=0.1008  doc#21  →  L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 4] score=0.0907  doc#24  →  La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "[ 5] score=0.0000  doc#13  →  Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "\n",
      "Query: 'pooling et jugement de pertinence gradué'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5202  doc#25  →  Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "[ 2] score=0.1469  doc#9  →  La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "[ 3] score=0.1015  doc#4  →  Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 4] score=0.0900  doc#42  →  Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 5] score=0.0886  doc#5  →  BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "\n",
      "Query: 'quelle métrique pour la pertinence multi-niveaux ?'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3686  doc#9  →  La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "[ 2] score=0.2855  doc#25  →  Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "[ 3] score=0.1950  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 4] score=0.1676  doc#30  →  La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\n",
      "[ 5] score=0.1020  doc#11  →  Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "\n",
      "Query: 'recherche multilingue avec SBERT ou E5'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3662  doc#19  →  Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 2] score=0.1950  doc#41  →  TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 3] score=0.1471  doc#49  →  Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\n",
      "[ 4] score=0.1409  doc#7  →  La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 5] score=0.1222  doc#30  →  La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\n",
      "\n",
      "Query: 'RAG pour questions médicales'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3209  doc#8  →  RAG (Retrieval-Augmented Generation) combine récupération de passages et modèles génératifs pour produire des réponses sourcées.\n",
      "[ 2] score=0.2408  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 3] score=0.1820  doc#51  →  En RAG, l'ordre : retrieve → read → generate ; la qualité du retrieve détermine souvent 80% du succès perçu.\n",
      "[ 4] score=0.1371  doc#16  →  Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "[ 5] score=0.1259  doc#11  →  Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "\n",
      "Query: \"désambiguïser l'acronyme IR selon le contexte\"\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3033  doc#39  →  La désambiguïsation des acronymes (ex. 'IR' = 'information retrieval' ou 'imagerie par résonance') dépend du contexte.\n",
      "[ 2] score=0.2127  doc#7  →  La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 3] score=0.1401  doc#33  →  URLs et hashtags (#IR, #NLP) perturbent parfois la segmentation en tokens.\n",
      "[ 4] score=0.1167  doc#24  →  La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "[ 5] score=0.1142  doc#0  →  La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "\n",
      "Query: 'recherche juridique: articles et alinéas'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.4273  doc#28  →  En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "[ 2] score=0.1478  doc#20  →  Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 3] score=0.1091  doc#14  →  Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 4] score=0.1079  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 5] score=0.1012  doc#18  →  FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "\n",
      "Query: 'recettes: pondération TF simple vs BM25'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5539  doc#29  →  Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "[ 2] score=0.1506  doc#3  →  TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 3] score=0.1478  doc#42  →  Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 4] score=0.1444  doc#41  →  TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 5] score=0.1353  doc#1  →  Un pipeline RI comporte souvent : prétraitement, indexation, pondération, scoring, puis évaluation des résultats.\n",
      "\n",
      "Query: 'HNSW vs FAISS vs Annoy pour ANN'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5378  doc#18  →  FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "[ 2] score=0.1331  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 3] score=0.1057  doc#34  →  Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 4] score=0.1032  doc#37  →  La réduction de dimension (PCA) ou la quantification des vecteurs (PQ, IVFPQ) accélère l'ANN au prix d'une légère perte de rappel.\n",
      "[ 5] score=0.0758  doc#16  →  Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "\n",
      "Query: 'hybrid search: combiner BM25 et embeddings'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.2729  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 2] score=0.2262  doc#42  →  Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 3] score=0.1915  doc#45  →  Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 4] score=0.1679  doc#20  →  Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 5] score=0.1598  doc#5  →  BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "\n",
      "Query: 'cross-encoder pour reranking des top-k'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6972  doc#36  →  Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "[ 2] score=0.1246  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 3] score=0.1069  doc#32  →  D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "[ 4] score=0.0852  doc#8  →  RAG (Retrieval-Augmented Generation) combine récupération de passages et modèles génératifs pour produire des réponses sourcées.\n",
      "[ 5] score=0.0824  doc#0  →  La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "\n",
      "Query: 'quantification des vecteurs (IVFPQ) et rappels'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.4295  doc#37  →  La réduction de dimension (PCA) ou la quantification des vecteurs (PQ, IVFPQ) accélère l'ANN au prix d'une légère perte de rappel.\n",
      "[ 2] score=0.1814  doc#32  →  D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "[ 3] score=0.1367  doc#5  →  BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 4] score=0.1241  doc#44  →  La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 5] score=0.0982  doc#2  →  Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "\n",
      "Query: 'pondérer le champ title plus que body'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.7359  doc#38  →  Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "[ 2] score=0.1086  doc#18  →  FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "[ 3] score=0.0890  doc#24  →  La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "[ 4] score=0.0705  doc#11  →  Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 5] score=0.0404  doc#50  →  La normalisation Unicode (NFC/NFKD) affecte le traitement des diacritiques (é/ê/e).\n",
      "\n",
      "Query: 'tf–idf (variante typographique) explication'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5149  doc#41  →  TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 2] score=0.3941  doc#3  →  TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 3] score=0.3645  doc#17  →  Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 4] score=0.1755  doc#29  →  Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "[ 5] score=0.0000  doc#52  →  Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "\n",
      "Query: 'embeding denses (typo) utilité'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6466  doc#44  →  La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 2] score=0.1712  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 3] score=0.1678  doc#6  →  Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "[ 4] score=0.0000  doc#52  →  Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "[ 5] score=0.0000  doc#13  →  Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "\n",
      "Query: 'Okapi-BM25 formule'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5015  doc#42  →  Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 2] score=0.3218  doc#4  →  Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=0.1464  doc#31  →  Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 4] score=0.1285  doc#43  →  Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 5] score=0.1241  doc#20  →  Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "\n",
      "Query: 'vector search sparse or dense'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6043  doc#45  →  Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 2] score=0.2320  doc#7  →  La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 3] score=0.2083  doc#20  →  Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 4] score=0.0869  doc#19  →  Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 5] score=0.0000  doc#52  →  Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "\n",
      "Query: 'BM25 sans normalisation de longueur'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5377  doc#43  →  Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 2] score=0.3624  doc#4  →  Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=0.3453  doc#47  →  Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 4] score=0.3328  doc#5  →  BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 5] score=0.2420  doc#42  →  Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Vectorisation TF-IDF\n",
    "tfidf_vec = TfidfVectorizer(lowercase=True, stop_words=None, norm=\"l2\")\n",
    "X_tfidf = tfidf_vec.fit_transform(corpus)\n",
    "\n",
    "def tfidf_search(query: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    q_vec = tfidf_vec.transform([query])\n",
    "    scores = cosine_similarity(q_vec, X_tfidf).ravel()\n",
    "    doc_ids = np.arange(X_tfidf.shape[0])\n",
    "    return doc_ids, scores\n",
    "\n",
    "for q in queries:\n",
    "    ids, sc = tfidf_search(q)\n",
    "    show_results(q, ids, sc, top_k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faaa534",
   "metadata": {},
   "source": [
    "\n",
    "## 3) **BM25** (Okapi)\n",
    "\n",
    "**Idée** : une fonction de scoring inspirée des modèles probabilistes (Okapi BM25) qui corrige certains biais de fréquence et **normalise la longueur des documents**.\n",
    "\n",
    "**Score BM25** pour un terme \\(t\\), un document \\(d\\) :\n",
    "\\[\n",
    "\\text{score}(d, q) = \\sum_{t \\in q} \\text{idf}(t) \\cdot\n",
    "\\frac{ tf_{t,d} (k_1 + 1)}{ tf_{t,d} + k_1\\big(1 - b + b\\,\\frac{|d|}{\\overline{|d|}}\\big) }\n",
    "\\]\n",
    "- \\(k_1\\) règle la saturation (souvent entre 1.2 et 2.0).  \n",
    "- \\(b\\) contrôle la normalisation par longueur (souvent ~0.75).  \n",
    "- \\(\\overline{|d|}\\) est la longueur moyenne des documents.\n",
    "\n",
    "On implémente une **version compacte** de BM25 pour notre mini‑corpus, sans dépendances externes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3670267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: 'comment fonctionne BM25 (k1, b) pour le ranking ?'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=5.8060  doc#42  →  Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 2] score=4.8605  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 3] score=4.5743  doc#4  →  Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 4] score=2.9294  doc#11  →  Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 5] score=2.8425  doc#6  →  Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "\n",
      "Query: 'différence entre sac de mots et TF-IDF'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=6.4035  doc#2  →  Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 2] score=6.4035  doc#40  →  Le sac de mots (bag of words) est simple et robuste mais ne capture pas la sémantique profonde.\n",
      "[ 3] score=4.5066  doc#3  →  TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 4] score=2.9351  doc#41  →  TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 5] score=2.4462  doc#11  →  Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "\n",
      "Query: 'CountVectorizer vs TfidfVectorizer scikit-learn'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=12.9604  doc#16  →  Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "[ 2] score=0.0000  doc#52  →  Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "[ 3] score=0.0000  doc#25  →  Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "[ 4] score=0.0000  doc#23  →  Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 5] score=0.0000  doc#22  →  MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "\n",
      "Query: 'bm25 ranking vs dense retrieval'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=5.8060  doc#42  →  Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 2] score=4.5743  doc#4  →  Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=2.9656  doc#7  →  La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 4] score=2.8690  doc#45  →  Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 5] score=2.7786  doc#19  →  Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "\n",
      "Query: 'quels avantages des embeddings denses pour la sémantique ?'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=9.1372  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 2] score=7.8606  doc#6  →  Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "[ 3] score=3.7465  doc#40  →  Le sac de mots (bag of words) est simple et robuste mais ne capture pas la sémantique profonde.\n",
      "[ 4] score=3.2848  doc#41  →  TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 5] score=3.1594  doc#44  →  La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "\n",
      "Query: 'liste de stopwords en français et impact sur la précision'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=6.6747  doc#48  →  Le choix des stop words en français diffère de l'anglais (ex. 'au', 'aux', 'des', 'du').\n",
      "[ 2] score=5.1448  doc#4  →  Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=4.6711  doc#28  →  En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "[ 4] score=4.5452  doc#24  →  La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "[ 5] score=4.5031  doc#27  →  Dans le domaine médical, la précision terminologique est cruciale (ex. 'hypertension artérielle').\n",
      "\n",
      "Query: 'lemmatisation vs stemming pour le français'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=4.6369  doc#48  →  Le choix des stop words en français diffère de l'anglais (ex. 'au', 'aux', 'des', 'du').\n",
      "[ 2] score=4.2644  doc#13  →  Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "[ 3] score=4.2644  doc#10  →  La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "[ 4] score=3.7574  doc#12  →  La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "[ 5] score=2.9294  doc#11  →  Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "\n",
      "Query: 'normalisation des accents et diacritiques'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=7.8081  doc#50  →  La normalisation Unicode (NFC/NFKD) affecte le traitement des diacritiques (é/ê/e).\n",
      "[ 2] score=4.4684  doc#5  →  BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 3] score=3.2879  doc#43  →  Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 4] score=2.9948  doc#10  →  La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "[ 5] score=2.8672  doc#32  →  D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "\n",
      "Query: \"gerer les fautes de frappe en recherche d'information\"\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=9.4719  doc#14  →  Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 2] score=5.3895  doc#0  →  La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "[ 3] score=4.2805  doc#28  →  En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "[ 4] score=3.4191  doc#44  →  La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 5] score=3.1470  doc#48  →  Le choix des stop words en français diffère de l'anglais (ex. 'au', 'aux', 'des', 'du').\n",
      "\n",
      "Query: 'traiter les hashtags et urls dans les documents'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=8.9715  doc#33  →  URLs et hashtags (#IR, #NLP) perturbent parfois la segmentation en tokens.\n",
      "[ 2] score=4.9979  doc#26  →  Les requêtes peuvent être multilingues ; les modèles multilingues mappent plusieurs langues dans le même espace.\n",
      "[ 3] score=4.4492  doc#3  →  TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 4] score=4.2541  doc#38  →  Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "[ 5] score=4.1279  doc#6  →  Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "\n",
      "Query: 'comparer MAP, MRR et nDCG@10'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=4.4838  doc#21  →  L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 2] score=3.4231  doc#22  →  MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "[ 3] score=1.2292  doc#20  →  Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 4] score=1.1259  doc#5  →  BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 5] score=1.1027  doc#32  →  D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "\n",
      "Query: \"datasets d'évaluation: TREC, MS MARCO, BEIR\"\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=10.9169  doc#23  →  Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 2] score=0.0000  doc#52  →  Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "[ 3] score=0.0000  doc#25  →  Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "[ 4] score=0.0000  doc#22  →  MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "[ 5] score=0.0000  doc#21  →  L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "\n",
      "Query: 'pooling et jugement de pertinence gradué'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=11.4831  doc#25  →  Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "[ 2] score=3.1202  doc#9  →  La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "[ 3] score=1.9781  doc#42  →  Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 4] score=1.7939  doc#4  →  Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 5] score=1.7863  doc#5  →  BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "\n",
      "Query: 'quelle métrique pour la pertinence multi-niveaux ?'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=7.5842  doc#9  →  La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "[ 2] score=3.4188  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 3] score=3.2218  doc#25  →  Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "[ 4] score=2.3118  doc#6  →  Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "[ 5] score=2.3118  doc#41  →  TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "\n",
      "Query: 'recherche multilingue avec SBERT ou E5'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=4.0192  doc#49  →  Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\n",
      "[ 2] score=3.7788  doc#7  →  La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 3] score=3.6557  doc#30  →  La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\n",
      "[ 4] score=1.9387  doc#20  →  Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 5] score=1.8201  doc#18  →  FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "\n",
      "Query: 'RAG pour questions médicales'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=5.3478  doc#8  →  RAG (Retrieval-Augmented Generation) combine récupération de passages et modèles génératifs pour produire des réponses sourcées.\n",
      "[ 2] score=2.6118  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 3] score=2.2290  doc#16  →  Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "[ 4] score=1.8775  doc#19  →  Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 5] score=1.8201  doc#11  →  Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "\n",
      "Query: \"désambiguïser l'acronyme IR selon le contexte\"\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=3.8839  doc#7  →  La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 2] score=1.8940  doc#24  →  La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "[ 3] score=1.3094  doc#50  →  La normalisation Unicode (NFC/NFKD) affecte le traitement des diacritiques (é/ê/e).\n",
      "[ 4] score=1.2638  doc#49  →  Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\n",
      "[ 5] score=1.2638  doc#17  →  Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "\n",
      "Query: 'recherche juridique: articles et alinéas'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=3.1678  doc#20  →  Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 2] score=2.6391  doc#18  →  FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "[ 3] score=2.6391  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 4] score=2.0039  doc#7  →  La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 5] score=1.9387  doc#30  →  La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\n",
      "\n",
      "Query: 'recettes: pondération TF simple vs BM25'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=6.7592  doc#29  →  Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "[ 2] score=3.2314  doc#40  →  Le sac de mots (bag of words) est simple et robuste mais ne capture pas la sémantique profonde.\n",
      "[ 3] score=2.4916  doc#3  →  TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 4] score=2.4757  doc#42  →  Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 5] score=2.3951  doc#20  →  Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "\n",
      "Query: 'HNSW vs FAISS vs Annoy pour ANN'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=7.0554  doc#18  →  FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "[ 2] score=2.6118  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 3] score=2.2290  doc#16  →  Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "[ 4] score=1.8775  doc#19  →  Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 5] score=1.8201  doc#11  →  Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "\n",
      "Query: 'hybrid search: combiner BM25 et embeddings'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=6.0925  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 2] score=3.6243  doc#20  →  Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 3] score=3.3774  doc#42  →  Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 4] score=2.9351  doc#6  →  Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "[ 5] score=2.7334  doc#47  →  Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "\n",
      "Query: 'cross-encoder pour reranking des top-k'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=11.6517  doc#36  →  Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "[ 2] score=2.8228  doc#8  →  RAG (Retrieval-Augmented Generation) combine récupération de passages et modèles génératifs pour produire des réponses sourcées.\n",
      "[ 3] score=2.7391  doc#41  →  TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 4] score=2.6118  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 5] score=2.5153  doc#0  →  La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "\n",
      "Query: 'quantification des vecteurs (IVFPQ) et rappels'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=6.3842  doc#37  →  La réduction de dimension (PCA) ou la quantification des vecteurs (PQ, IVFPQ) accélère l'ANN au prix d'une légère perte de rappel.\n",
      "[ 2] score=2.9351  doc#44  →  La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 3] score=2.8672  doc#32  →  D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "[ 4] score=2.5043  doc#5  →  BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 5] score=2.1002  doc#2  →  Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "\n",
      "Query: 'pondérer le champ title plus que body'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=11.1895  doc#38  →  Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "[ 2] score=3.0248  doc#18  →  FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "[ 3] score=1.8940  doc#24  →  La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "[ 4] score=1.3094  doc#50  →  La normalisation Unicode (NFC/NFKD) affecte le traitement des diacritiques (é/ê/e).\n",
      "[ 5] score=1.2638  doc#49  →  Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\n",
      "\n",
      "Query: 'tf–idf (variante typographique) explication'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=3.4231  doc#41  →  TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 2] score=0.0000  doc#52  →  Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "[ 3] score=0.0000  doc#12  →  La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "[ 4] score=0.0000  doc#23  →  Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 5] score=0.0000  doc#22  →  MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "\n",
      "Query: 'embeding denses (typo) utilité'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=2.6936  doc#35  →  La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 2] score=2.6137  doc#6  →  Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "[ 3] score=2.6137  doc#44  →  La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 4] score=0.0000  doc#52  →  Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "[ 5] score=0.0000  doc#13  →  Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "\n",
      "Query: 'Okapi-BM25 formule'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=3.8839  doc#42  →  Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 2] score=0.0000  doc#52  →  Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "[ 3] score=0.0000  doc#12  →  La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "[ 4] score=0.0000  doc#23  →  Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 5] score=0.0000  doc#22  →  MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "\n",
      "Query: 'vector search sparse or dense'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=17.8988  doc#45  →  Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 2] score=2.9656  doc#7  →  La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 3] score=2.7786  doc#19  →  Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 4] score=0.0000  doc#52  →  Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "[ 5] score=0.0000  doc#13  →  Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "\n",
      "Query: 'BM25 sans normalisation de longueur'\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=7.4656  doc#4  →  Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 2] score=6.1882  doc#43  →  Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 3] score=5.4750  doc#5  →  BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 4] score=4.7852  doc#47  →  Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 5] score=3.5521  doc#42  →  Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "class BM25OkapiMini:\n",
    "    def __init__(self, docs: List[str], tokenizer=str.split, k1: float = 1.5, b: float = 0.75):\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        self.docs_tokens = [self.tokenizer(d.lower()) for d in docs]\n",
    "        self.doc_lens = [len(toks) for toks in self.docs_tokens]\n",
    "        self.avgdl = sum(self.doc_lens) / len(self.doc_lens)\n",
    "        \n",
    "       \n",
    "        self.tf = [Counter(toks) for toks in self.docs_tokens]\n",
    "        \n",
    "        # document frequencies\n",
    "        df = Counter()\n",
    "        for counter in self.tf:\n",
    "            for term in counter:\n",
    "                df[term] += 1\n",
    "        self.df = df\n",
    "        self.N = len(docs)\n",
    "        \n",
    "    \n",
    "        self.idf = {}\n",
    "        for term, df_t in self.df.items():\n",
    "            # idf BM25 classique (Robertson/Sparck Jones)\n",
    "            self.idf[term] = math.log((self.N - df_t + 0.5) / (df_t + 0.5) + 1)\n",
    "    \n",
    "    def score(self, query: str) -> np.ndarray:\n",
    "        q_terms = self.tokenizer(query.lower())\n",
    "        scores = np.zeros(self.N, dtype=float)\n",
    "        for i, tf_i in enumerate(self.tf):\n",
    "            dl = self.doc_lens[i]\n",
    "            denom_norm = self.k1 * (1 - self.b + self.b * dl / self.avgdl)\n",
    "            s = 0.0\n",
    "            for t in q_terms:\n",
    "                if t not in tf_i:\n",
    "                    continue\n",
    "                idf_t = self.idf.get(t, 0.0)\n",
    "                tf_td = tf_i[t]\n",
    "                s += idf_t * ((tf_td * (self.k1 + 1)) / (tf_td + denom_norm))\n",
    "            scores[i] = s\n",
    "        return scores\n",
    "\n",
    "bm25 = BM25OkapiMini(corpus)\n",
    "\n",
    "def bm25_search(query: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    scores = bm25.score(query)\n",
    "    doc_ids = np.arange(len(corpus))\n",
    "    return doc_ids, scores\n",
    "\n",
    "for q in queries:\n",
    "    ids, sc = bm25_search(q)\n",
    "    show_results(q, ids, sc, top_k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6aac40",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Comparaison rapide des méthodes\n",
    "\n",
    "On lance les trois méthodes pour chaque requête et on compare visuellement les **Top‑3** résultats.  \n",
    "Le but est d'observer des **différences de ranking** dues à la pondération (TF‑IDF) et à la normalisation de longueur (BM25).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80486589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Query: 'comment fonctionne BM25 (k1, b) pour le ranking ?' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.3254) Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "  2. (0.3254) Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "  3. (0.3078) La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "TF-IDF:\n",
      "  1. (0.4227) Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "  2. (0.3281) Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "  3. (0.2362) La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "BM25:\n",
      "  1. (5.8060) Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "  2. (4.8605) La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "  3. (4.5743) Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "\n",
      "=== Query: 'différence entre sac de mots et TF-IDF' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.4352) Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "  2. (0.3849) Le sac de mots (bag of words) est simple et robuste mais ne capture pas la sémantique profonde.\n",
      "  3. (0.3397) Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "TF-IDF:\n",
      "  1. (0.3752) Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "  2. (0.3405) TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "  3. (0.3350) TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "BM25:\n",
      "  1. (6.4035) Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "  2. (6.4035) Le sac de mots (bag of words) est simple et robuste mais ne capture pas la sémantique profonde.\n",
      "  3. (4.5066) TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "\n",
      "=== Query: 'CountVectorizer vs TfidfVectorizer scikit-learn' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.6325) Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "  2. (0.1179) Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "  3. (0.0000) Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "TF-IDF:\n",
      "  1. (0.7073) Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "  2. (0.1090) Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "  3. (0.0000) Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "BM25:\n",
      "  1. (12.9604) Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "  2. (0.0000) Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "  3. (0.0000) Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "\n",
      "=== Query: 'bm25 ranking vs dense retrieval' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.3638) Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "  2. (0.2500) Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "  3. (0.1890) Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "TF-IDF:\n",
      "  1. (0.3414) Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "  2. (0.2191) Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "  3. (0.2083) Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "BM25:\n",
      "  1. (5.8060) Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "  2. (4.5743) Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "  3. (2.9656) La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "\n",
      "=== Query: 'quels avantages des embeddings denses pour la sémantique ?' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.6556) La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "  2. (0.5103) Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "  3. (0.4454) La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "TF-IDF:\n",
      "  1. (0.6009) La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "  2. (0.4884) Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "  3. (0.4705) La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "BM25:\n",
      "  1. (9.1372) La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "  2. (7.8606) Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "  3. (3.7465) Le sac de mots (bag of words) est simple et robuste mais ne capture pas la sémantique profonde.\n",
      "\n",
      "=== Query: 'liste de stopwords en français et impact sur la précision' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.4677) Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "  2. (0.3780) En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "  3. (0.3769) Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "TF-IDF:\n",
      "  1. (0.2444) Le choix des stop words en français diffère de l'anglais (ex. 'au', 'aux', 'des', 'du').\n",
      "  2. (0.2271) Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "  3. (0.1965) Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "BM25:\n",
      "  1. (6.6747) Le choix des stop words en français diffère de l'anglais (ex. 'au', 'aux', 'des', 'du').\n",
      "  2. (5.1448) Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "  3. (4.6711) En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "\n",
      "=== Query: 'lemmatisation vs stemming pour le français' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.3254) Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "  2. (0.2860) La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "  3. (0.2631) La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "TF-IDF:\n",
      "  1. (0.3525) La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "  2. (0.2109) Le choix des stop words en français diffère de l'anglais (ex. 'au', 'aux', 'des', 'du').\n",
      "  3. (0.1861) Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "BM25:\n",
      "  1. (4.6369) Le choix des stop words en français diffère de l'anglais (ex. 'au', 'aux', 'des', 'du').\n",
      "  2. (4.2644) Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "  3. (4.2644) La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "\n",
      "=== Query: 'normalisation des accents et diacritiques' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.4880) BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "  2. (0.4743) D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "  3. (0.4243) La normalisation Unicode (NFC/NFKD) affecte le traitement des diacritiques (é/ê/e).\n",
      "TF-IDF:\n",
      "  1. (0.3842) La normalisation Unicode (NFC/NFKD) affecte le traitement des diacritiques (é/ê/e).\n",
      "  2. (0.3365) La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "  3. (0.2360) BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "BM25:\n",
      "  1. (7.8081) La normalisation Unicode (NFC/NFKD) affecte le traitement des diacritiques (é/ê/e).\n",
      "  2. (4.4684) BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "  3. (3.2879) Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "\n",
      "=== Query: \"gerer les fautes de frappe en recherche d'information\" ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.5669) Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "  2. (0.3780) Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "  3. (0.3299) La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "TF-IDF:\n",
      "  1. (0.4482) Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "  2. (0.2121) La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "  3. (0.1874) La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "BM25:\n",
      "  1. (9.4719) Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "  2. (5.3895) La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "  3. (4.2805) En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "\n",
      "=== Query: 'traiter les hashtags et urls dans les documents' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.4303) La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "  2. (0.4167) Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "  3. (0.3824) Les requêtes peuvent être multilingues ; les modèles multilingues mappent plusieurs langues dans le même espace.\n",
      "TF-IDF:\n",
      "  1. (0.3543) URLs et hashtags (#IR, #NLP) perturbent parfois la segmentation en tokens.\n",
      "  2. (0.1892) Les requêtes peuvent être multilingues ; les modèles multilingues mappent plusieurs langues dans le même espace.\n",
      "  3. (0.1710) TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "BM25:\n",
      "  1. (8.9715) URLs et hashtags (#IR, #NLP) perturbent parfois la segmentation en tokens.\n",
      "  2. (4.9979) Les requêtes peuvent être multilingues ; les modèles multilingues mappent plusieurs langues dans le même espace.\n",
      "  3. (4.4492) TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "\n",
      "=== Query: 'comparer MAP, MRR et nDCG@10' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.5345) L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "  2. (0.2500) Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "  3. (0.2425) MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "TF-IDF:\n",
      "  1. (0.5219) L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "  2. (0.2653) MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "  3. (0.0694) Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "BM25:\n",
      "  1. (4.4838) L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "  2. (3.4231) MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "  3. (1.2292) Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "\n",
      "=== Query: \"datasets d'évaluation: TREC, MS MARCO, BEIR\" ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.4781) Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "  2. (0.1240) Un pipeline RI comporte souvent : prétraitement, indexation, pondération, scoring, puis évaluation des résultats.\n",
      "  3. (0.1195) L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "TF-IDF:\n",
      "  1. (0.5771) Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "  2. (0.1027) Un pipeline RI comporte souvent : prétraitement, indexation, pondération, scoring, puis évaluation des résultats.\n",
      "  3. (0.1008) L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "BM25:\n",
      "  1. (10.9169) Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "  2. (0.0000) Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "  3. (0.0000) Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "\n",
      "=== Query: 'pooling et jugement de pertinence gradué' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.4781) Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "  2. (0.3381) Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "  3. (0.3254) Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "TF-IDF:\n",
      "  1. (0.5202) Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "  2. (0.1469) La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "  3. (0.1015) Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "BM25:\n",
      "  1. (11.4831) Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "  2. (3.1202) La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "  3. (1.9781) Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "\n",
      "=== Query: 'quelle métrique pour la pertinence multi-niveaux ?' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.4472) La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "  2. (0.4104) La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "  3. (0.3508) La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "TF-IDF:\n",
      "  1. (0.3686) La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "  2. (0.2855) Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "  3. (0.1950) La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "BM25:\n",
      "  1. (7.5842) La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "  2. (3.4188) La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "  3. (3.2218) Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "\n",
      "=== Query: 'recherche multilingue avec SBERT ou E5' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.3464) Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "  2. (0.2390) La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\n",
      "  3. (0.2390) La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "TF-IDF:\n",
      "  1. (0.3662) Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "  2. (0.1950) TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "  3. (0.1471) Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\n",
      "BM25:\n",
      "  1. (4.0192) Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\n",
      "  2. (3.7788) La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "  3. (3.6557) La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\n",
      "\n",
      "=== Query: 'RAG pour questions médicales' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.3536) RAG (Retrieval-Augmented Generation) combine récupération de passages et modèles génératifs pour produire des réponses sourcées.\n",
      "  2. (0.3244) La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "  3. (0.2236) Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "TF-IDF:\n",
      "  1. (0.3209) RAG (Retrieval-Augmented Generation) combine récupération de passages et modèles génératifs pour produire des réponses sourcées.\n",
      "  2. (0.2408) La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "  3. (0.1820) En RAG, l'ordre : retrieve → read → generate ; la qualité du retrieve détermine souvent 80% du succès perçu.\n",
      "BM25:\n",
      "  1. (5.3478) RAG (Retrieval-Augmented Generation) combine récupération de passages et modèles génératifs pour produire des réponses sourcées.\n",
      "  2. (2.6118) La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "  3. (2.2290) Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "\n",
      "=== Query: \"désambiguïser l'acronyme IR selon le contexte\" ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.3198) La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "  2. (0.2582) La désambiguïsation des acronymes (ex. 'IR' = 'information retrieval' ou 'imagerie par résonance') dépend du contexte.\n",
      "  3. (0.2425) Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "TF-IDF:\n",
      "  1. (0.3033) La désambiguïsation des acronymes (ex. 'IR' = 'information retrieval' ou 'imagerie par résonance') dépend du contexte.\n",
      "  2. (0.2127) La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "  3. (0.1401) URLs et hashtags (#IR, #NLP) perturbent parfois la segmentation en tokens.\n",
      "BM25:\n",
      "  1. (3.8839) La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "  2. (1.8940) La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "  3. (1.3094) La normalisation Unicode (NFC/NFKD) affecte le traitement des diacritiques (é/ê/e).\n",
      "\n",
      "=== Query: 'recherche juridique: articles et alinéas' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.4009) En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "  2. (0.3750) Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "  3. (0.2582) FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "TF-IDF:\n",
      "  1. (0.4273) En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "  2. (0.1478) Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "  3. (0.1091) Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "BM25:\n",
      "  1. (3.1678) Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "  2. (2.6391) FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "  3. (2.6391) La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "\n",
      "=== Query: 'recettes: pondération TF simple vs BM25' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.4781) Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "  2. (0.2169) Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "  3. (0.1754) TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "TF-IDF:\n",
      "  1. (0.5539) Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "  2. (0.1506) TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "  3. (0.1478) Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "BM25:\n",
      "  1. (6.7592) Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "  2. (3.2314) Le sac de mots (bag of words) est simple et robuste mais ne capture pas la sémantique profonde.\n",
      "  3. (2.4916) TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "\n",
      "=== Query: 'HNSW vs FAISS vs Annoy pour ANN' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.4619) FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "  2. (0.2052) La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "  3. (0.1414) Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "TF-IDF:\n",
      "  1. (0.5378) FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "  2. (0.1331) La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "  3. (0.1057) Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "BM25:\n",
      "  1. (7.0554) FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "  2. (2.6118) La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "  3. (2.2290) Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "\n",
      "=== Query: 'hybrid search: combiner BM25 et embeddings' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.3750) Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "  2. (0.3638) Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "  3. (0.3441) La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "TF-IDF:\n",
      "  1. (0.2729) La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "  2. (0.2262) Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "  3. (0.1915) Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "BM25:\n",
      "  1. (6.0925) La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "  2. (3.6243) Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "  3. (3.3774) Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "\n",
      "=== Query: 'cross-encoder pour reranking des top-k' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.5620) Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "  2. (0.2887) D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "  3. (0.2041) RAG (Retrieval-Augmented Generation) combine récupération de passages et modèles génératifs pour produire des réponses sourcées.\n",
      "TF-IDF:\n",
      "  1. (0.6972) Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "  2. (0.1246) La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "  3. (0.1069) D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "BM25:\n",
      "  1. (11.6517) Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "  2. (2.8228) RAG (Retrieval-Augmented Generation) combine récupération de passages et modèles génératifs pour produire des réponses sourcées.\n",
      "  3. (2.7391) TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "\n",
      "=== Query: 'quantification des vecteurs (IVFPQ) et rappels' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.4743) D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "  2. (0.3904) BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "  3. (0.3578) La réduction de dimension (PCA) ou la quantification des vecteurs (PQ, IVFPQ) accélère l'ANN au prix d'une légère perte de rappel.\n",
      "TF-IDF:\n",
      "  1. (0.4295) La réduction de dimension (PCA) ou la quantification des vecteurs (PQ, IVFPQ) accélère l'ANN au prix d'une légère perte de rappel.\n",
      "  2. (0.1814) D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "  3. (0.1367) BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "BM25:\n",
      "  1. (6.3842) La réduction de dimension (PCA) ou la quantification des vecteurs (PQ, IVFPQ) accélère l'ANN au prix d'une légère perte de rappel.\n",
      "  2. (2.9351) La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "  3. (2.8672) D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "\n",
      "=== Query: 'pondérer le champ title plus que body' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.6124) Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "  2. (0.2611) La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "  3. (0.1980) Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "TF-IDF:\n",
      "  1. (0.7359) Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "  2. (0.1086) FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "  3. (0.0890) La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "BM25:\n",
      "  1. (11.1895) Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "  2. (3.0248) FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "  3. (1.8940) La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "\n",
      "=== Query: 'tf–idf (variante typographique) explication' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.5547) TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "  2. (0.4082) TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "  3. (0.3922) Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "TF-IDF:\n",
      "  1. (0.5149) TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "  2. (0.3941) TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "  3. (0.3645) Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "BM25:\n",
      "  1. (3.4231) TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "  2. (0.0000) Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "  3. (0.0000) La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "\n",
      "=== Query: 'embeding denses (typo) utilité' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.6172) La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "  2. (0.1768) Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "  3. (0.1622) La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "TF-IDF:\n",
      "  1. (0.6466) La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "  2. (0.1712) La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "  3. (0.1678) Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "BM25:\n",
      "  1. (2.6936) La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "  2. (2.6137) Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "  3. (2.6137) La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "\n",
      "=== Query: 'Okapi-BM25 formule' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.5145) Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "  2. (0.2673) Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "  3. (0.2500) Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "TF-IDF:\n",
      "  1. (0.5015) Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "  2. (0.3218) Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "  3. (0.1464) Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "BM25:\n",
      "  1. (3.8839) Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "  2. (0.0000) Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "  3. (0.0000) La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "\n",
      "=== Query: 'vector search sparse or dense' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.5976) Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "  2. (0.2390) La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "  3. (0.2236) Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "TF-IDF:\n",
      "  1. (0.6043) Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "  2. (0.2320) La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "  3. (0.2083) Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "BM25:\n",
      "  1. (17.8988) Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "  2. (2.9656) La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "  3. (2.7786) Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "\n",
      "=== Query: 'BM25 sans normalisation de longueur' ===\n",
      "BoW/CountVectorizer:\n",
      "  1. (0.6202) Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "  2. (0.5071) Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "  3. (0.4767) Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "TF-IDF:\n",
      "  1. (0.5377) Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "  2. (0.3624) Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "  3. (0.3453) Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "BM25:\n",
      "  1. (7.4656) Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "  2. (6.1882) Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "  3. (5.4750) BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def topk_indices(scores, k=3):\n",
    "    return np.argsort(scores)[::-1][:k]\n",
    "\n",
    "def compare_methods(query: str, k: int = 3):\n",
    "    ids_bow, sc_bow = bow_search(query)\n",
    "    ids_tfidf, sc_tfidf = tfidf_search(query)\n",
    "    ids_bm25, sc_bm25 = bm25_search(query)\n",
    "    \n",
    "    top_bow = topk_indices(sc_bow, k)\n",
    "    top_tfidf = topk_indices(sc_tfidf, k)\n",
    "    top_bm25 = topk_indices(sc_bm25, k)\n",
    "    \n",
    "    print(f\"\\n=== Query: {query!r} ===\")\n",
    "    print(\"BoW/CountVectorizer:\")\n",
    "    for r, i in enumerate(top_bow, 1):\n",
    "        print(f\"  {r}. ({sc_bow[i]:.4f}) {corpus[i]}\")\n",
    "    print(\"TF-IDF:\")\n",
    "    for r, i in enumerate(top_tfidf, 1):\n",
    "        print(f\"  {r}. ({sc_tfidf[i]:.4f}) {corpus[i]}\")\n",
    "    print(\"BM25:\")\n",
    "    for r, i in enumerate(top_bm25, 1):\n",
    "        print(f\"  {r}. ({sc_bm25[i]:.4f}) {corpus[i]}\")\n",
    "\n",
    "for q in queries:\n",
    "    compare_methods(q, k=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4f3e78",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Notes pratiques & lien avec la suite (dense + Hugging Face)\n",
    "\n",
    "- Sur de **grands corpus**, BM25 et TF‑IDF restent des **baselines solides** et étonnamment compétitives.  \n",
    "- Pour des requêtes courtes, BM25 a souvent un avantage sur **BoW** car il normalise la longueur et pondère mieux les mots rares.  \n",
    "- Ces méthodes ignorent le **sens** et les **synonymes** — d'où l'intérêt des **représentations denses** , souvent construites avec des modèles *Hugging Face* (p. ex. `sentence-transformers` basés sur BERT).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d094c83",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
