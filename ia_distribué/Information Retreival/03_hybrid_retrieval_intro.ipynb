{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20092b55",
   "metadata": {},
   "source": [
    "\n",
    "# Section 3 — Hybrid Retrieval Strategy (sparse + dense)\n",
    "\n",
    "Le **retrieval hybride** combine le meilleur des deux mondes :\n",
    "- **Sparse** (lexical) : sensibilité au *recouvrement exact* des termes — BoW/TF‑IDF/BM25.\n",
    "- **Dense** (sémantique) : capture le **sens** et les **paraphrases** via des **embeddings**.\n",
    "\n",
    "But : **améliorer la pertinence** en fusionnant les signaux.  \n",
    "Nous allons :\n",
    "1. Construire un index **sparse** (TF‑IDF, avec option BM25 mini).\n",
    "2. Générer des **embeddings de phrases** avec un modèle **Hugging Face** (Sentence-Transformers).\n",
    "3. Récupérer les *Top‑N* candidats dans chaque espace.\n",
    "4. **Fusionner** (somme pondérée après normalisation, **RRF** — *Reciprocal Rank Fusion*).\n",
    "5. Visualiser l'effet de la fusion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb0d82e",
   "metadata": {},
   "source": [
    "\n",
    "## Pré-requis (installation)\n",
    "Exécutez **une seule fois** si nécessaire (commenté par défaut) :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c65436",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %pip -q install --upgrade pip\n",
    "# %pip -q install scikit-learn sentence-transformers torch --extra-index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1b48d7",
   "metadata": {},
   "source": [
    "\n",
    "## Données d'exemple\n",
    "On réutilise un mini-corpus multi-lingue et quelques requêtes pour observer les différences entre sparse, dense et hybride.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b2d16c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus: 53 documents | Ex. requêtes: ['comment fonctionne BM25 (k1, b) pour le ranking ?', 'différence entre sac de mots et TF-IDF', 'CountVectorizer vs TfidfVectorizer scikit-learn'] ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import List, Tuple, Dict\n",
    "import numpy as np\n",
    "\n",
    "corpus = [\n",
    "    # --- Concepts généraux & définitions ---\n",
    "    \"La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\",\n",
    "    \"Un pipeline RI comporte souvent : prétraitement, indexation, pondération, scoring, puis évaluation des résultats.\",\n",
    "    \"Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\",\n",
    "    \"TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\",\n",
    "    \"Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\",\n",
    "    \"BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\",\n",
    "    \"Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\",\n",
    "    \"La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\",\n",
    "    \"RAG (Retrieval-Augmented Generation) combine récupération de passages et modèles génératifs pour produire des réponses sourcées.\",\n",
    "    \"La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\",\n",
    "\n",
    "    # --- Prétraitement & normalisation ---\n",
    "    \"La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\",\n",
    "    \"Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\",\n",
    "    \"La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\",\n",
    "    \"Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\",\n",
    "    \"Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\",\n",
    "    \"Les entités nommées (NER) aident à conserver des unités sémantiques comme 'OpenAI' ou 'Europe/Paris'.\",\n",
    "\n",
    "    # --- Outils & bibliothèques ---\n",
    "    \"Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\",\n",
    "    \"Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\",\n",
    "    \"FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\",\n",
    "    \"Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\",\n",
    "    \"Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\",\n",
    "\n",
    "    # --- Évaluation ---\n",
    "    \"L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\",\n",
    "    \"MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\",\n",
    "    \"Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\",\n",
    "    \"La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\",\n",
    "    \"Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\",\n",
    "\n",
    "    # --- Multilingue & domaines ---\n",
    "    \"Les requêtes peuvent être multilingues ; les modèles multilingues mappent plusieurs langues dans le même espace.\",\n",
    "    \"Dans le domaine médical, la précision terminologique est cruciale (ex. 'hypertension artérielle').\",\n",
    "    \"En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\",\n",
    "    \"Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\",\n",
    "    \"La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\",\n",
    "\n",
    "    # --- Bruit, longueur et structure ---\n",
    "    \"Certains documents sont très courts: 'BM25 expliqué rapidement'.\",\n",
    "    \"D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\",\n",
    "    \"URLs et hashtags (#IR, #NLP) perturbent parfois la segmentation en tokens.\",\n",
    "    \"Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\",\n",
    "\n",
    "    # --- Recherche hybride & reranking ---\n",
    "    \"La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\",\n",
    "    \"Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\",\n",
    "    \"La réduction de dimension (PCA) ou la quantification des vecteurs (PQ, IVFPQ) accélère l'ANN au prix d'une légère perte de rappel.\",\n",
    "    \"Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\",\n",
    "    \"La désambiguïsation des acronymes (ex. 'IR' = 'information retrieval' ou 'imagerie par résonance') dépend du contexte.\",\n",
    "\n",
    "    # --- Cas concrets & exemples mixtes ---\n",
    "    \"Le sac de mots (bag of words) est simple et robuste mais ne capture pas la sémantique profonde.\",\n",
    "    \"TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\",\n",
    "    \"Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\",\n",
    "    \"Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\",\n",
    "    \"La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\",\n",
    "    \"Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\",\n",
    "    \"L'alignement d'espaces multilingues permet 'apprentissage' ≈ 'learning' ≈ 'aprendizaje'.\",\n",
    "    \"Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\",\n",
    "    \"Le choix des stop words en français diffère de l'anglais (ex. 'au', 'aux', 'des', 'du').\",\n",
    "    \"Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\",\n",
    "    \"La normalisation Unicode (NFC/NFKD) affecte le traitement des diacritiques (é/ê/e).\",\n",
    "    \"En RAG, l'ordre : retrieve → read → generate ; la qualité du retrieve détermine souvent 80% du succès perçu.\",\n",
    "    \"Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\"\n",
    "]\n",
    "\n",
    "queries = [\n",
    "    # Requêtes ciblées IR\n",
    "    \"comment fonctionne BM25 (k1, b) pour le ranking ?\",\n",
    "    \"différence entre sac de mots et TF-IDF\",\n",
    "    \"CountVectorizer vs TfidfVectorizer scikit-learn\",\n",
    "    \"bm25 ranking vs dense retrieval\",\n",
    "    \"quels avantages des embeddings denses pour la sémantique ?\",\n",
    "\n",
    "    # Prétraitement & robustesse\n",
    "    \"liste de stopwords en français et impact sur la précision\",\n",
    "    \"lemmatisation vs stemming pour le français\",\n",
    "    \"normalisation des accents et diacritiques\",\n",
    "    \"gerer les fautes de frappe en recherche d'information\",\n",
    "    \"traiter les hashtags et urls dans les documents\",\n",
    "\n",
    "    # Évaluation\n",
    "    \"comparer MAP, MRR et nDCG@10\",\n",
    "    \"datasets d'évaluation: TREC, MS MARCO, BEIR\",\n",
    "    \"pooling et jugement de pertinence gradué\",\n",
    "    \"quelle métrique pour la pertinence multi-niveaux ?\",\n",
    "\n",
    "    # Multilingue & domaines\n",
    "    \"recherche multilingue avec SBERT ou E5\",\n",
    "    \"RAG pour questions médicales\",\n",
    "    \"désambiguïser l'acronyme IR selon le contexte\",\n",
    "    \"recherche juridique: articles et alinéas\",\n",
    "    \"recettes: pondération TF simple vs BM25\",\n",
    "\n",
    "    # ANN & systèmes\n",
    "    \"HNSW vs FAISS vs Annoy pour ANN\",\n",
    "    \"hybrid search: combiner BM25 et embeddings\",\n",
    "    \"cross-encoder pour reranking des top-k\",\n",
    "    \"quantification des vecteurs (IVFPQ) et rappels\",\n",
    "    \"pondérer le champ title plus que body\",\n",
    "\n",
    "    # Requêtes bruitées / mixtes / typos\n",
    "    \"tf–idf (variante typographique) explication\",\n",
    "    \"embeding denses (typo) utilité\",\n",
    "    \"Okapi-BM25 formule\",\n",
    "    \"vector search sparse or dense\",\n",
    "    \"BM25 sans normalisation de longueur\"\n",
    "]\n",
    "doc_ids_all = np.arange(len(corpus))\n",
    "print(f\"Corpus: {len(corpus)} documents | Ex. requêtes: {queries[:3]} ...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c154b49",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Composant **Sparse**\n",
    "Nous utilisons **TF‑IDF** (scikit-learn) pour la base, et proposons en option une implémentation **BM25** compacte.  \n",
    "On calcule la **similarité cosinus** entre la requête vectorisée et les documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7b5431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# --- TF-IDF ---\n",
    "tfidf_vec = TfidfVectorizer(lowercase=True)\n",
    "X_tfidf = tfidf_vec.fit_transform(corpus)\n",
    "\n",
    "def search_tfidf(query: str) -> np.ndarray:\n",
    "    q = tfidf_vec.transform([query])\n",
    "    return cosine_similarity(q, X_tfidf).ravel()\n",
    "\n",
    "# --- BM25 mini (optionnel) ---\n",
    "class BM25OkapiMini:\n",
    "    def __init__(self, docs: List[str], tokenizer=str.split, k1: float = 1.5, b: float = 0.75):\n",
    "        self.k1, self.b = k1, b\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokens = [tokenizer(d.lower()) for d in docs]\n",
    "        self.tf = [Counter(toks) for toks in self.tokens]\n",
    "        self.doc_lens = [len(toks) for toks in self.tokens]\n",
    "        self.avgdl = sum(self.doc_lens) / len(self.doc_lens)\n",
    "        self.N = len(docs)\n",
    "        # df + idf\n",
    "        df = Counter()\n",
    "        for c in self.tf:\n",
    "            for t in c: df[t] += 1\n",
    "        self.idf = {t: math.log((self.N - df_t + 0.5) / (df_t + 0.5) + 1) for t, df_t in df.items()}\n",
    "    def score(self, query: str) -> np.ndarray:\n",
    "        q_terms = self.tokenizer(query.lower())\n",
    "        scores = np.zeros(self.N, dtype=float)\n",
    "        for i, c in enumerate(self.tf):\n",
    "            denom_norm = self.k1 * (1 - self.b + self.b * self.doc_lens[i] / self.avgdl)\n",
    "            s = 0.0\n",
    "            for t in q_terms:\n",
    "                if t not in c: continue\n",
    "                tf_td = c[t]\n",
    "                idf_t = self.idf.get(t, 0.0)\n",
    "                s += idf_t * ((tf_td * (self.k1 + 1)) / (tf_td + denom_norm))\n",
    "            scores[i] = s\n",
    "        return scores\n",
    "\n",
    "bm25 = BM25OkapiMini(corpus)\n",
    "\n",
    "def search_bm25(query: str) -> np.ndarray:\n",
    "    return bm25.score(query)\n",
    "\n",
    "def sparse_search(query: str, method: str = \"tfidf\") -> np.ndarray:\n",
    "    if method == \"bm25\":\n",
    "        return search_bm25(query)\n",
    "    return search_tfidf(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1588406",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Composant **Dense** (Hugging Face — Sentence-Transformers)\n",
    "\n",
    "On choisit un modèle **multilingue** pour encoder les documents et les requêtes :  \n",
    "`sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` (rapide et efficace).  \n",
    "On **normalise** les embeddings pour que le produit interne équivaille au **cosinus**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d68cd2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\salah\\anaconda3\\envs\\ragllm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\salah\\anaconda3\\envs\\ragllm\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\salah\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-multilingual-MiniLM-L12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\salah\\anaconda3\\envs\\ragllm\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %pip -q install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "ST_MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "st_model = SentenceTransformer(ST_MODEL_NAME)\n",
    "doc_vecs_dense = st_model.encode(corpus, convert_to_numpy=True, normalize_embeddings=True)\n",
    "\n",
    "def dense_search(query: str) -> np.ndarray:\n",
    "    q = st_model.encode([query], convert_to_numpy=True, normalize_embeddings=True)[0]\n",
    "    return doc_vecs_dense @ q  # cosinus (car normalisé)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5958306a",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Stratégies de **Fusion**\n",
    "Deux recettes simples et efficaces :\n",
    "\n",
    "- **Somme pondérée** après **normalisation** des scores  :  \n",
    "\n",
    "\n",
    "- **RRF — Reciprocal Rank Fusion** : combine des **rangs** plutôt que des scores, robuste aux échelles différentes :  \n",
    "\n",
    "  avec un **k** typiquement 60 (valeur classique).\n",
    "\n",
    "> En pratique : on **restreint** la fusion à l'union des *Top‑N* candidats de chaque méthode (ex. N=8 ou 50).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d91d164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def minmax_norm(x: np.ndarray) -> np.ndarray:\n",
    "    lo, hi = float(np.min(x)), float(np.max(x))\n",
    "    if hi - lo < 1e-12:\n",
    "        return np.zeros_like(x)  # tous égaux\n",
    "    return (x - lo) / (hi - lo)\n",
    "\n",
    "def weighted_sum_fusion(scores_sparse: np.ndarray, scores_dense: np.ndarray, alpha: float = 0.5) -> np.ndarray:\n",
    "    s_sp = minmax_norm(scores_sparse)\n",
    "    s_de = minmax_norm(scores_dense)\n",
    "    return alpha * s_sp + (1 - alpha) * s_de\n",
    "\n",
    "def rrf_fusion(scores_list: List[np.ndarray], k: int = 60) -> np.ndarray:\n",
    "    # Convertit des scores → rangs (ordre décroissant)\n",
    "    n = scores_list[0].shape[0]\n",
    "    rrf = np.zeros(n, dtype=float)\n",
    "    for scores in scores_list:\n",
    "        ranks = np.argsort(np.argsort(-scores))  # rang 0 = meilleur\n",
    "        # RRF additionne 1 / (k + rank)\n",
    "        rrf += 1.0 / (k + ranks.astype(float))\n",
    "    return rrf\n",
    "\n",
    "def topn_union(scores: np.ndarray, n: int) -> set:\n",
    "    idx = np.argsort(scores)[::-1][:n]\n",
    "    return set(idx.tolist())\n",
    "\n",
    "def hybrid_search(query: str, sparse_method=\"tfidf\", top_n_each: int = 8, alpha: float = 0.5, k_rrf: int = 60) -> dict:\n",
    "    # 1) Scores bruts\n",
    "    sp = sparse_search(query, method=sparse_method)\n",
    "    de = dense_search(query)\n",
    "    # 2) Restreindre à l'union des top-N\n",
    "    cand = sorted(list(topn_union(sp, top_n_each) | topn_union(de, top_n_each)))\n",
    "    # 3) Préparer des vecteurs \"candidats only\"\n",
    "    mask = np.zeros_like(sp, dtype=bool); mask[cand] = True\n",
    "    sp_c = np.where(mask, sp, np.min(sp) - 1.0)  # pour garder les tailles constantes\n",
    "    de_c = np.where(mask, de, np.min(de) - 1.0)\n",
    "    # 4) Fusions\n",
    "    fused_ws = weighted_sum_fusion(sp_c, de_c, alpha=alpha)\n",
    "    fused_rrf = rrf_fusion([sp_c, de_c], k=k_rrf)\n",
    "    return {\n",
    "        \"sparse_scores\": sp,\n",
    "        \"dense_scores\": de,\n",
    "        \"candidates\": cand,\n",
    "        \"weighted_sum\": fused_ws,\n",
    "        \"rrf\": fused_rrf\n",
    "    }\n",
    "\n",
    "def show_ranking(title: str, scores: np.ndarray, k: int = 5):\n",
    "    order = np.argsort(scores)[::-1][:k]\n",
    "    print(f\"\\n{title}\")\n",
    "    print(\"-\" * 80)\n",
    "    for r, i in enumerate(order, 1):\n",
    "        print(f\"[{r:>2}] score={scores[i]:.4f}  doc#{i} → {corpus[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543e3620",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Démo : de bout en bout\n",
    "Pour chaque requête :\n",
    "1. Top‑N **sparse** (TF‑IDF par défaut).\n",
    "2. Top‑N **dense** (Sentence-Transformers).\n",
    "3. **Fusion** par somme pondérée (α=0.5) et **RRF** (k=60).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e82eb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: 'comment fonctionne BM25 (k1, b) pour le ranking ?' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.4227  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 2] score=0.3281  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 3] score=0.2362  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 4] score=0.2105  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 5] score=0.1755  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "\n",
      "Query: 'comment fonctionne BM25 (k1, b) pour le ranking ?' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.7573  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 2] score=0.7281  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 3] score=0.6313  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 4] score=0.5743  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 5] score=0.5527  doc#36 → Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "\n",
      "Query: 'comment fonctionne BM25 (k1, b) pour le ranking ?' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=1.0000  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 2] score=0.9588  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 3] score=0.8912  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 4] score=0.8692  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 5] score=0.8289  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "\n",
      "Query: 'comment fonctionne BM25 (k1, b) pour le ranking ?' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0333  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 2] score=0.0328  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 3] score=0.0320  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 4] score=0.0315  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 5] score=0.0304  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "\n",
      "Query: 'différence entre sac de mots et TF-IDF' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3752  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 2] score=0.3405  doc#41 → TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 3] score=0.3350  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 4] score=0.2734  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 5] score=0.2729  doc#40 → Le sac de mots (bag of words) est simple et robuste mais ne capture pas la sémantique profonde.\n",
      "\n",
      "Query: 'différence entre sac de mots et TF-IDF' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.7087  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 2] score=0.6753  doc#41 → TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 3] score=0.5140  doc#40 → Le sac de mots (bag of words) est simple et robuste mais ne capture pas la sémantique profonde.\n",
      "[ 4] score=0.4094  doc#39 → La désambiguïsation des acronymes (ex. 'IR' = 'information retrieval' ou 'imagerie par résonance') dépend du contexte.\n",
      "[ 5] score=0.3931  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "\n",
      "Query: 'différence entre sac de mots et TF-IDF' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9854  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 2] score=0.9773  doc#41 → TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 3] score=0.9037  doc#40 → Le sac de mots (bag of words) est simple et robuste mais ne capture pas la sémantique profonde.\n",
      "[ 4] score=0.8998  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 5] score=0.8673  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "\n",
      "Query: 'différence entre sac de mots et TF-IDF' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0328  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 2] score=0.0328  doc#41 → TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 3] score=0.0321  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "[ 4] score=0.0318  doc#40 → Le sac de mots (bag of words) est simple et robuste mais ne capture pas la sémantique profonde.\n",
      "[ 5] score=0.0315  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "\n",
      "Query: 'CountVectorizer vs TfidfVectorizer scikit-learn' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.7073  doc#16 → Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "[ 2] score=0.1090  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 3] score=0.0000  doc#52 → Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "[ 4] score=0.0000  doc#13 → Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "[ 5] score=0.0000  doc#23 → Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "\n",
      "Query: 'CountVectorizer vs TfidfVectorizer scikit-learn' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8649  doc#16 → Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "[ 2] score=0.4032  doc#41 → TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 3] score=0.3944  doc#23 → Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 4] score=0.3934  doc#29 → Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "[ 5] score=0.3858  doc#9 → La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "\n",
      "Query: 'CountVectorizer vs TfidfVectorizer scikit-learn' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=1.0000  doc#16 → Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "[ 2] score=0.6799  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 3] score=0.6689  doc#41 → TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 4] score=0.6665  doc#23 → Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 5] score=0.6663  doc#29 → Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "\n",
      "Query: 'CountVectorizer vs TfidfVectorizer scikit-learn' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0333  doc#16 → Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "[ 2] score=0.0320  doc#23 → Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 3] score=0.0311  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 4] score=0.0307  doc#41 → TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 5] score=0.0303  doc#36 → Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "\n",
      "Query: 'bm25 ranking vs dense retrieval' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3414  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 2] score=0.2191  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=0.2083  doc#20 → Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 4] score=0.1529  doc#39 → La désambiguïsation des acronymes (ex. 'IR' = 'information retrieval' ou 'imagerie par résonance') dépend du contexte.\n",
      "[ 5] score=0.1442  doc#8 → RAG (Retrieval-Augmented Generation) combine récupération de passages et modèles génératifs pour produire des réponses sourcées.\n",
      "\n",
      "Query: 'bm25 ranking vs dense retrieval' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5641  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 2] score=0.5455  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 3] score=0.5289  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 4] score=0.5253  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 5] score=0.5164  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "\n",
      "Query: 'bm25 ranking vs dense retrieval' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=1.0000  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 2] score=0.9434  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=0.9128  doc#20 → Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 4] score=0.9018  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 5] score=0.8955  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "\n",
      "Query: 'bm25 ranking vs dense retrieval' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0333  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 2] score=0.0325  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=0.0310  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 4] score=0.0309  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 5] score=0.0308  doc#20 → Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "\n",
      "Query: 'quels avantages des embeddings denses pour la sémantique ?' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6009  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 2] score=0.4884  doc#6 → Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "[ 3] score=0.4705  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 4] score=0.1556  doc#32 → D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "[ 5] score=0.1365  doc#40 → Le sac de mots (bag of words) est simple et robuste mais ne capture pas la sémantique profonde.\n",
      "\n",
      "Query: 'quels avantages des embeddings denses pour la sémantique ?' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6374  doc#6 → Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "[ 2] score=0.4954  doc#32 → D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "[ 3] score=0.4910  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 4] score=0.4607  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 5] score=0.4600  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "\n",
      "Query: 'quels avantages des embeddings denses pour la sémantique ?' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9649  doc#6 → Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "[ 2] score=0.9403  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 3] score=0.9100  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 4] score=0.8131  doc#32 → D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "[ 5] score=0.7756  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "\n",
      "Query: 'quels avantages des embeddings denses pour la sémantique ?' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0331  doc#6 → Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "[ 2] score=0.0323  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 3] score=0.0323  doc#32 → D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "[ 4] score=0.0323  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 5] score=0.0306  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "\n",
      "Query: 'liste de stopwords en français et impact sur la précision' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.2444  doc#48 → Le choix des stop words en français diffère de l'anglais (ex. 'au', 'aux', 'des', 'du').\n",
      "[ 2] score=0.2271  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=0.1965  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 4] score=0.1654  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 5] score=0.1474  doc#27 → Dans le domaine médical, la précision terminologique est cruciale (ex. 'hypertension artérielle').\n",
      "\n",
      "Query: 'liste de stopwords en français et impact sur la précision' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5391  doc#14 → Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 2] score=0.5217  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 3] score=0.5199  doc#48 → Le choix des stop words en français diffère de l'anglais (ex. 'au', 'aux', 'des', 'du').\n",
      "[ 4] score=0.4765  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 5] score=0.4647  doc#9 → La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "\n",
      "Query: 'liste de stopwords en français et impact sur la précision' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9940  doc#48 → Le choix des stop words en français diffère de l'anglais (ex. 'au', 'aux', 'des', 'du').\n",
      "[ 2] score=0.9753  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 3] score=0.9488  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 4] score=0.9324  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 5] score=0.9286  doc#27 → Dans le domaine médical, la précision terminologique est cruciale (ex. 'hypertension artérielle').\n",
      "\n",
      "Query: 'liste de stopwords en français et impact sur la précision' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0328  doc#48 → Le choix des stop words en français diffère de l'anglais (ex. 'au', 'aux', 'des', 'du').\n",
      "[ 2] score=0.0325  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 3] score=0.0317  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 4] score=0.0312  doc#14 → Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 5] score=0.0311  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "\n",
      "Query: 'lemmatisation vs stemming pour le français' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3525  doc#10 → La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "[ 2] score=0.2109  doc#48 → Le choix des stop words en français diffère de l'anglais (ex. 'au', 'aux', 'des', 'du').\n",
      "[ 3] score=0.1861  doc#13 → Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "[ 4] score=0.1646  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 5] score=0.1509  doc#12 → La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "\n",
      "Query: 'lemmatisation vs stemming pour le français' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6311  doc#12 → La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "[ 2] score=0.4691  doc#48 → Le choix des stop words en français diffère de l'anglais (ex. 'au', 'aux', 'des', 'du').\n",
      "[ 3] score=0.4183  doc#13 → Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "[ 4] score=0.3889  doc#10 → La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "[ 5] score=0.3325  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "\n",
      "Query: 'lemmatisation vs stemming pour le français' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9333  doc#10 → La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "[ 2] score=0.9254  doc#12 → La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "[ 3] score=0.9031  doc#48 → Le choix des stop words en français diffère de l'anglais (ex. 'au', 'aux', 'des', 'du').\n",
      "[ 4] score=0.8799  doc#13 → Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "[ 5] score=0.8483  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "\n",
      "Query: 'lemmatisation vs stemming pour le français' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0328  doc#48 → Le choix des stop words en français diffère de l'anglais (ex. 'au', 'aux', 'des', 'du').\n",
      "[ 2] score=0.0325  doc#10 → La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "[ 3] score=0.0323  doc#12 → La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "[ 4] score=0.0323  doc#13 → Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "[ 5] score=0.0315  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "\n",
      "Query: 'normalisation des accents et diacritiques' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3842  doc#50 → La normalisation Unicode (NFC/NFKD) affecte le traitement des diacritiques (é/ê/e).\n",
      "[ 2] score=0.3365  doc#10 → La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "[ 3] score=0.2360  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 4] score=0.1911  doc#32 → D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "[ 5] score=0.1430  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "\n",
      "Query: 'normalisation des accents et diacritiques' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8041  doc#10 → La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "[ 2] score=0.6063  doc#50 → La normalisation Unicode (NFC/NFKD) affecte le traitement des diacritiques (é/ê/e).\n",
      "[ 3] score=0.4391  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 4] score=0.4071  doc#46 → L'alignement d'espaces multilingues permet 'apprentissage' ≈ 'learning' ≈ 'aprendizaje'.\n",
      "[ 5] score=0.3522  doc#14 → Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "\n",
      "Query: 'normalisation des accents et diacritiques' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9828  doc#10 → La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "[ 2] score=0.9467  doc#50 → La normalisation Unicode (NFC/NFKD) affecte le traitement des diacritiques (é/ê/e).\n",
      "[ 3] score=0.7752  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 4] score=0.7661  doc#48 → Le choix des stop words en français diffère de l'anglais (ex. 'au', 'aux', 'des', 'du').\n",
      "[ 5] score=0.7629  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "\n",
      "Query: 'normalisation des accents et diacritiques' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0331  doc#50 → La normalisation Unicode (NFC/NFKD) affecte le traitement des diacritiques (é/ê/e).\n",
      "[ 2] score=0.0331  doc#10 → La normalisation inclut les accents, la casse, la tokenisation, le stemming et la lemmatisation.\n",
      "[ 3] score=0.0304  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 4] score=0.0302  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 5] score=0.0301  doc#14 → Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "\n",
      "Query: \"gerer les fautes de frappe en recherche d'information\" — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.4482  doc#14 → Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 2] score=0.2121  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 3] score=0.1874  doc#0 → La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "[ 4] score=0.1450  doc#28 → En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "[ 5] score=0.1448  doc#38 → Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "\n",
      "Query: \"gerer les fautes de frappe en recherche d'information\" — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.4693  doc#14 → Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 2] score=0.4437  doc#0 → La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "[ 3] score=0.4213  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 4] score=0.4128  doc#49 → Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\n",
      "[ 5] score=0.3890  doc#39 → La désambiguïsation des acronymes (ex. 'IR' = 'information retrieval' ou 'imagerie par résonance') dépend du contexte.\n",
      "\n",
      "Query: \"gerer les fautes de frappe en recherche d'information\" — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=1.0000  doc#14 → Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 2] score=0.9016  doc#0 → La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "[ 3] score=0.8628  doc#39 → La désambiguïsation des acronymes (ex. 'IR' = 'information retrieval' ou 'imagerie par résonance') dépend du contexte.\n",
      "[ 4] score=0.8557  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 5] score=0.8545  doc#38 → Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "\n",
      "Query: \"gerer les fautes de frappe en recherche d'information\" — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0333  doc#14 → Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 2] score=0.0325  doc#0 → La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "[ 3] score=0.0311  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 4] score=0.0310  doc#39 → La désambiguïsation des acronymes (ex. 'IR' = 'information retrieval' ou 'imagerie par résonance') dépend du contexte.\n",
      "[ 5] score=0.0308  doc#28 → En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "\n",
      "Query: 'traiter les hashtags et urls dans les documents' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3543  doc#33 → URLs et hashtags (#IR, #NLP) perturbent parfois la segmentation en tokens.\n",
      "[ 2] score=0.1892  doc#26 → Les requêtes peuvent être multilingues ; les modèles multilingues mappent plusieurs langues dans le même espace.\n",
      "[ 3] score=0.1710  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 4] score=0.1653  doc#12 → La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "[ 5] score=0.1588  doc#14 → Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "\n",
      "Query: 'traiter les hashtags et urls dans les documents' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6314  doc#33 → URLs et hashtags (#IR, #NLP) perturbent parfois la segmentation en tokens.\n",
      "[ 2] score=0.4827  doc#32 → D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "[ 3] score=0.4127  doc#38 → Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "[ 4] score=0.3558  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 5] score=0.3279  doc#0 → La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "\n",
      "Query: 'traiter les hashtags et urls dans les documents' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=1.0000  doc#33 → URLs et hashtags (#IR, #NLP) perturbent parfois la segmentation en tokens.\n",
      "[ 2] score=0.8609  doc#38 → Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "[ 3] score=0.8417  doc#32 → D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "[ 4] score=0.8192  doc#0 → La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "[ 5] score=0.8171  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "\n",
      "Query: 'traiter les hashtags et urls dans les documents' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0333  doc#33 → URLs et hashtags (#IR, #NLP) perturbent parfois la segmentation en tokens.\n",
      "[ 2] score=0.0315  doc#38 → Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "[ 3] score=0.0311  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 4] score=0.0309  doc#26 → Les requêtes peuvent être multilingues ; les modèles multilingues mappent plusieurs langues dans le même espace.\n",
      "[ 5] score=0.0307  doc#32 → D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "\n",
      "Query: 'comparer MAP, MRR et nDCG@10' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5219  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 2] score=0.2653  doc#22 → MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "[ 3] score=0.0694  doc#20 → Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 4] score=0.0660  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 5] score=0.0566  doc#32 → D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "\n",
      "Query: 'comparer MAP, MRR et nDCG@10' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6279  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 2] score=0.5091  doc#22 → MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "[ 3] score=0.4459  doc#23 → Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 4] score=0.4261  doc#36 → Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "[ 5] score=0.3720  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "\n",
      "Query: 'comparer MAP, MRR et nDCG@10' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=1.0000  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 2] score=0.8797  doc#22 → MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "[ 3] score=0.7842  doc#23 → Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 4] score=0.7674  doc#36 → Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "[ 5] score=0.7620  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "\n",
      "Query: 'comparer MAP, MRR et nDCG@10' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0333  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 2] score=0.0328  doc#22 → MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "[ 3] score=0.0308  doc#20 → Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 4] score=0.0304  doc#23 → Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 5] score=0.0301  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "\n",
      "Query: \"datasets d'évaluation: TREC, MS MARCO, BEIR\" — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5771  doc#23 → Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 2] score=0.1027  doc#1 → Un pipeline RI comporte souvent : prétraitement, indexation, pondération, scoring, puis évaluation des résultats.\n",
      "[ 3] score=0.1008  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 4] score=0.0907  doc#24 → La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "[ 5] score=0.0000  doc#13 → Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "\n",
      "Query: \"datasets d'évaluation: TREC, MS MARCO, BEIR\" — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6297  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 2] score=0.5951  doc#23 → Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 3] score=0.4468  doc#1 → Un pipeline RI comporte souvent : prétraitement, indexation, pondération, scoring, puis évaluation des résultats.\n",
      "[ 4] score=0.4234  doc#22 → MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "[ 5] score=0.4086  doc#36 → Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "\n",
      "Query: \"datasets d'évaluation: TREC, MS MARCO, BEIR\" — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9891  doc#23 → Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 2] score=0.8490  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 3] score=0.7921  doc#1 → Un pipeline RI comporte souvent : prétraitement, indexation, pondération, scoring, puis évaluation des résultats.\n",
      "[ 4] score=0.7555  doc#24 → La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "[ 5] score=0.7522  doc#22 → MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "\n",
      "Query: \"datasets d'évaluation: TREC, MS MARCO, BEIR\" — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0331  doc#23 → Les jeux de données TREC, MS MARCO et BEIR sont des bancs d'essai courants.\n",
      "[ 2] score=0.0328  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 3] score=0.0325  doc#1 → Un pipeline RI comporte souvent : prétraitement, indexation, pondération, scoring, puis évaluation des résultats.\n",
      "[ 4] score=0.0310  doc#22 → MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "[ 5] score=0.0310  doc#49 → Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\n",
      "\n",
      "Query: 'pooling et jugement de pertinence gradué' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5202  doc#25 → Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "[ 2] score=0.1469  doc#9 → La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "[ 3] score=0.1015  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 4] score=0.0900  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 5] score=0.0886  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "\n",
      "Query: 'pooling et jugement de pertinence gradué' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.4513  doc#25 → Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "[ 2] score=0.4475  doc#9 → La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "[ 3] score=0.4090  doc#22 → MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "[ 4] score=0.3753  doc#14 → Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 5] score=0.3556  doc#24 → La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "\n",
      "Query: 'pooling et jugement de pertinence gradué' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=1.0000  doc#25 → Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "[ 2] score=0.8760  doc#9 → La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "[ 3] score=0.8239  doc#14 → Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 4] score=0.8228  doc#22 → MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "[ 5] score=0.8074  doc#24 → La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "\n",
      "Query: 'pooling et jugement de pertinence gradué' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0333  doc#25 → Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "[ 2] score=0.0328  doc#9 → La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "[ 3] score=0.0306  doc#14 → Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 4] score=0.0304  doc#22 → MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "[ 5] score=0.0304  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "\n",
      "Query: 'quelle métrique pour la pertinence multi-niveaux ?' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3686  doc#9 → La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "[ 2] score=0.2855  doc#25 → Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "[ 3] score=0.1950  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 4] score=0.1676  doc#30 → La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\n",
      "[ 5] score=0.1020  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "\n",
      "Query: 'quelle métrique pour la pertinence multi-niveaux ?' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5350  doc#9 → La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "[ 2] score=0.4378  doc#25 → Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "[ 3] score=0.4245  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 4] score=0.4155  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 5] score=0.3934  doc#46 → L'alignement d'espaces multilingues permet 'apprentissage' ≈ 'learning' ≈ 'aprendizaje'.\n",
      "\n",
      "Query: 'quelle métrique pour la pertinence multi-niveaux ?' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=1.0000  doc#9 → La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "[ 2] score=0.9393  doc#25 → Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "[ 3] score=0.8504  doc#30 → La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\n",
      "[ 4] score=0.8461  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 5] score=0.8431  doc#6 → Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "\n",
      "Query: 'quelle métrique pour la pertinence multi-niveaux ?' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0333  doc#9 → La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "[ 2] score=0.0328  doc#25 → Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "[ 3] score=0.0308  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 4] score=0.0304  doc#30 → La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\n",
      "[ 5] score=0.0300  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "\n",
      "Query: 'recherche multilingue avec SBERT ou E5' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3662  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 2] score=0.1950  doc#41 → TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 3] score=0.1471  doc#49 → Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\n",
      "[ 4] score=0.1409  doc#7 → La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 5] score=0.1222  doc#30 → La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\n",
      "\n",
      "Query: 'recherche multilingue avec SBERT ou E5' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6588  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 2] score=0.5900  doc#26 → Les requêtes peuvent être multilingues ; les modèles multilingues mappent plusieurs langues dans le même espace.\n",
      "[ 3] score=0.4964  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 4] score=0.4541  doc#36 → Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "[ 5] score=0.4526  doc#46 → L'alignement d'espaces multilingues permet 'apprentissage' ≈ 'learning' ≈ 'aprendizaje'.\n",
      "\n",
      "Query: 'recherche multilingue avec SBERT ou E5' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=1.0000  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 2] score=0.8440  doc#26 → Les requêtes peuvent être multilingues ; les modèles multilingues mappent plusieurs langues dans le même espace.\n",
      "[ 3] score=0.8365  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 4] score=0.8037  doc#18 → FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "[ 5] score=0.8005  doc#36 → Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "\n",
      "Query: 'recherche multilingue avec SBERT ou E5' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0333  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 2] score=0.0308  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 3] score=0.0303  doc#30 → La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\n",
      "[ 4] score=0.0302  doc#7 → La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 5] score=0.0301  doc#26 → Les requêtes peuvent être multilingues ; les modèles multilingues mappent plusieurs langues dans le même espace.\n",
      "\n",
      "Query: 'RAG pour questions médicales' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3209  doc#8 → RAG (Retrieval-Augmented Generation) combine récupération de passages et modèles génératifs pour produire des réponses sourcées.\n",
      "[ 2] score=0.2408  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 3] score=0.1820  doc#51 → En RAG, l'ordre : retrieve → read → generate ; la qualité du retrieve détermine souvent 80% du succès perçu.\n",
      "[ 4] score=0.1371  doc#16 → Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "[ 5] score=0.1259  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "\n",
      "Query: 'RAG pour questions médicales' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.4306  doc#27 → Dans le domaine médical, la précision terminologique est cruciale (ex. 'hypertension artérielle').\n",
      "[ 2] score=0.2567  doc#30 → La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\n",
      "[ 3] score=0.2372  doc#49 → Le pré-traitement influence fortement les résultats, surtout avec de petites requêtes.\n",
      "[ 4] score=0.2263  doc#14 → Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 5] score=0.2228  doc#0 → La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "\n",
      "Query: 'RAG pour questions médicales' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8997  doc#8 → RAG (Retrieval-Augmented Generation) combine récupération de passages et modèles génératifs pour produire des réponses sourcées.\n",
      "[ 2] score=0.8785  doc#27 → Dans le domaine médical, la précision terminologique est cruciale (ex. 'hypertension artérielle').\n",
      "[ 3] score=0.8493  doc#51 → En RAG, l'ordre : retrieve → read → generate ; la qualité du retrieve détermine souvent 80% du succès perçu.\n",
      "[ 4] score=0.8493  doc#0 → La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "[ 5] score=0.8294  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "\n",
      "Query: 'RAG pour questions médicales' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0314  doc#27 → Dans le domaine médical, la précision terminologique est cruciale (ex. 'hypertension artérielle').\n",
      "[ 2] score=0.0310  doc#8 → RAG (Retrieval-Augmented Generation) combine récupération de passages et modèles génératifs pour produire des réponses sourcées.\n",
      "[ 3] score=0.0306  doc#51 → En RAG, l'ordre : retrieve → read → generate ; la qualité du retrieve détermine souvent 80% du succès perçu.\n",
      "[ 4] score=0.0306  doc#0 → La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "[ 5] score=0.0305  doc#30 → La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\n",
      "\n",
      "Query: \"désambiguïser l'acronyme IR selon le contexte\" — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.3033  doc#39 → La désambiguïsation des acronymes (ex. 'IR' = 'information retrieval' ou 'imagerie par résonance') dépend du contexte.\n",
      "[ 2] score=0.2127  doc#7 → La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 3] score=0.1401  doc#33 → URLs et hashtags (#IR, #NLP) perturbent parfois la segmentation en tokens.\n",
      "[ 4] score=0.1167  doc#24 → La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "[ 5] score=0.1142  doc#0 → La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "\n",
      "Query: \"désambiguïser l'acronyme IR selon le contexte\" — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8076  doc#39 → La désambiguïsation des acronymes (ex. 'IR' = 'information retrieval' ou 'imagerie par résonance') dépend du contexte.\n",
      "[ 2] score=0.3983  doc#28 → En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "[ 3] score=0.3801  doc#33 → URLs et hashtags (#IR, #NLP) perturbent parfois la segmentation en tokens.\n",
      "[ 4] score=0.3777  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 5] score=0.3712  doc#0 → La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "\n",
      "Query: \"désambiguïser l'acronyme IR selon le contexte\" — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=1.0000  doc#39 → La désambiguïsation des acronymes (ex. 'IR' = 'information retrieval' ou 'imagerie par résonance') dépend du contexte.\n",
      "[ 2] score=0.8142  doc#33 → URLs et hashtags (#IR, #NLP) perturbent parfois la segmentation en tokens.\n",
      "[ 3] score=0.8017  doc#0 → La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "[ 4] score=0.7953  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 5] score=0.7898  doc#7 → La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "\n",
      "Query: \"désambiguïser l'acronyme IR selon le contexte\" — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0333  doc#39 → La désambiguïsation des acronymes (ex. 'IR' = 'information retrieval' ou 'imagerie par résonance') dépend du contexte.\n",
      "[ 2] score=0.0323  doc#33 → URLs et hashtags (#IR, #NLP) perturbent parfois la segmentation en tokens.\n",
      "[ 3] score=0.0313  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 4] score=0.0312  doc#0 → La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "[ 5] score=0.0307  doc#7 → La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "\n",
      "Query: 'recherche juridique: articles et alinéas' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.4273  doc#28 → En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "[ 2] score=0.1478  doc#20 → Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 3] score=0.1091  doc#14 → Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 4] score=0.1079  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 5] score=0.1012  doc#18 → FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "\n",
      "Query: 'recherche juridique: articles et alinéas' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.4900  doc#28 → En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "[ 2] score=0.3138  doc#12 → La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "[ 3] score=0.2670  doc#13 → Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "[ 4] score=0.2169  doc#0 → La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "[ 5] score=0.1920  doc#30 → La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\n",
      "\n",
      "Query: 'recherche juridique: articles et alinéas' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=1.0000  doc#28 → En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "[ 2] score=0.8083  doc#12 → La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "[ 3] score=0.7932  doc#13 → Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "[ 4] score=0.7873  doc#0 → La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "[ 5] score=0.7825  doc#30 → La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\n",
      "\n",
      "Query: 'recherche juridique: articles et alinéas' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0333  doc#28 → En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "[ 2] score=0.0308  doc#14 → Les fautes de frappe et variantes orthographiques (ex. 'recherhe', 'recherche') pénalisent les méthodes exactes.\n",
      "[ 3] score=0.0307  doc#12 → La lemmatisation française nécessite de gérer les accords et les formes verbales composées.\n",
      "[ 4] score=0.0306  doc#0 → La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "[ 5] score=0.0306  doc#30 → La recherche académique bénéficie d'expressions multi-mots comme 'régression logistique' ou 'réseau de neurones'.\n",
      "\n",
      "Query: 'recettes: pondération TF simple vs BM25' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5539  doc#29 → Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "[ 2] score=0.1506  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 3] score=0.1478  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 4] score=0.1444  doc#41 → TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 5] score=0.1353  doc#1 → Un pipeline RI comporte souvent : prétraitement, indexation, pondération, scoring, puis évaluation des résultats.\n",
      "\n",
      "Query: 'recettes: pondération TF simple vs BM25' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.7097  doc#29 → Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "[ 2] score=0.5741  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 3] score=0.5687  doc#41 → TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 4] score=0.5462  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 5] score=0.5059  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "\n",
      "Query: 'recettes: pondération TF simple vs BM25' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=1.0000  doc#29 → Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "[ 2] score=0.8280  doc#41 → TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 3] score=0.8112  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 4] score=0.8052  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 5] score=0.7962  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "\n",
      "Query: 'recettes: pondération TF simple vs BM25' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0333  doc#29 → Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "[ 2] score=0.0320  doc#41 → TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 3] score=0.0318  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 4] score=0.0311  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 5] score=0.0307  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "\n",
      "Query: 'HNSW vs FAISS vs Annoy pour ANN' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5378  doc#18 → FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "[ 2] score=0.1331  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 3] score=0.1057  doc#34 → Les citations de code `pip install faiss-gpu` ou `from sklearn.feature_extraction.text import TfidfVectorizer` doivent être préservées.\n",
      "[ 4] score=0.1032  doc#37 → La réduction de dimension (PCA) ou la quantification des vecteurs (PQ, IVFPQ) accélère l'ANN au prix d'une légère perte de rappel.\n",
      "[ 5] score=0.0758  doc#16 → Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "\n",
      "Query: 'HNSW vs FAISS vs Annoy pour ANN' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5121  doc#18 → FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "[ 2] score=0.3559  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 3] score=0.3028  doc#39 → La désambiguïsation des acronymes (ex. 'IR' = 'information retrieval' ou 'imagerie par résonance') dépend du contexte.\n",
      "[ 4] score=0.2987  doc#28 → En droit, les synonymes et références croisées (articles, alinéas) créent de la variance lexicale.\n",
      "[ 5] score=0.2946  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "\n",
      "Query: 'HNSW vs FAISS vs Annoy pour ANN' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=1.0000  doc#18 → FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "[ 2] score=0.7955  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 3] score=0.7839  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 4] score=0.7787  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 5] score=0.7587  doc#39 → La désambiguïsation des acronymes (ex. 'IR' = 'information retrieval' ou 'imagerie par résonance') dépend du contexte.\n",
      "\n",
      "Query: 'HNSW vs FAISS vs Annoy pour ANN' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0333  doc#18 → FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "[ 2] score=0.0313  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 3] score=0.0311  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 4] score=0.0310  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 5] score=0.0308  doc#39 → La désambiguïsation des acronymes (ex. 'IR' = 'information retrieval' ou 'imagerie par résonance') dépend du contexte.\n",
      "\n",
      "Query: 'hybrid search: combiner BM25 et embeddings' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.2729  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 2] score=0.2262  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 3] score=0.1915  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 4] score=0.1679  doc#20 → Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 5] score=0.1598  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "\n",
      "Query: 'hybrid search: combiner BM25 et embeddings' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.7567  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 2] score=0.6310  doc#20 → Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 3] score=0.4900  doc#18 → FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "[ 4] score=0.4625  doc#36 → Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "[ 5] score=0.4359  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "\n",
      "Query: 'hybrid search: combiner BM25 et embeddings' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=1.0000  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 2] score=0.9229  doc#20 → Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 3] score=0.8885  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 4] score=0.8672  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 5] score=0.8512  doc#6 → Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "\n",
      "Query: 'hybrid search: combiner BM25 et embeddings' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0333  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 2] score=0.0323  doc#20 → Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 3] score=0.0318  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 4] score=0.0308  doc#18 → FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "[ 5] score=0.0308  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "\n",
      "Query: 'cross-encoder pour reranking des top-k' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6972  doc#36 → Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "[ 2] score=0.1246  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 3] score=0.1069  doc#32 → D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "[ 4] score=0.0852  doc#8 → RAG (Retrieval-Augmented Generation) combine récupération de passages et modèles génératifs pour produire des réponses sourcées.\n",
      "[ 5] score=0.0824  doc#0 → La recherche d'information (IR) vise à retrouver des documents pertinents pour un besoin utilisateur exprimé sous forme de requête.\n",
      "\n",
      "Query: 'cross-encoder pour reranking des top-k' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6948  doc#36 → Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "[ 2] score=0.4266  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 3] score=0.4105  doc#22 → MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "[ 4] score=0.3976  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 5] score=0.3897  doc#52 → Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "\n",
      "Query: 'cross-encoder pour reranking des top-k' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=1.0000  doc#36 → Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "[ 2] score=0.7262  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 3] score=0.7246  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 4] score=0.7237  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 5] score=0.7187  doc#22 → MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "\n",
      "Query: 'cross-encoder pour reranking des top-k' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0333  doc#36 → Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "[ 2] score=0.0311  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 3] score=0.0306  doc#32 → D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "[ 4] score=0.0306  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 5] score=0.0305  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "\n",
      "Query: 'quantification des vecteurs (IVFPQ) et rappels' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.4295  doc#37 → La réduction de dimension (PCA) ou la quantification des vecteurs (PQ, IVFPQ) accélère l'ANN au prix d'une légère perte de rappel.\n",
      "[ 2] score=0.1814  doc#32 → D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "[ 3] score=0.1367  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 4] score=0.1241  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 5] score=0.0982  doc#2 → Le modèle sac de mots ignore l'ordre des termes et représente un document par la fréquence des mots.\n",
      "\n",
      "Query: 'quantification des vecteurs (IVFPQ) et rappels' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6121  doc#37 → La réduction de dimension (PCA) ou la quantification des vecteurs (PQ, IVFPQ) accélère l'ANN au prix d'une légère perte de rappel.\n",
      "[ 2] score=0.5415  doc#7 → La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 3] score=0.5371  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 4] score=0.4604  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 5] score=0.4604  doc#9 → La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "\n",
      "Query: 'quantification des vecteurs (IVFPQ) et rappels' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=1.0000  doc#37 → La réduction de dimension (PCA) ou la quantification des vecteurs (PQ, IVFPQ) accélère l'ANN au prix d'une légère perte de rappel.\n",
      "[ 2] score=0.8509  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 3] score=0.8473  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 4] score=0.8284  doc#7 → La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 5] score=0.8150  doc#16 → Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "\n",
      "Query: 'quantification des vecteurs (IVFPQ) et rappels' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0333  doc#37 → La réduction de dimension (PCA) ou la quantification des vecteurs (PQ, IVFPQ) accélère l'ANN au prix d'une légère perte de rappel.\n",
      "[ 2] score=0.0317  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 3] score=0.0308  doc#21 → L'évaluation compare précision, rappel, F1, MAP, MRR, nDCG@k et taux de couverture des passages.\n",
      "[ 4] score=0.0305  doc#32 → D'autres sont longs et contiennent des sections, des listes, des liens et des tableaux qui influencent la tokenisation.\n",
      "[ 5] score=0.0304  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "\n",
      "Query: 'pondérer le champ title plus que body' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.7359  doc#38 → Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "[ 2] score=0.1086  doc#18 → FAISS, HNSW (hnswlib), Annoy et ScaNN accélèrent la recherche de plus proches voisins approximatifs (ANN).\n",
      "[ 3] score=0.0890  doc#24 → La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "[ 4] score=0.0705  doc#11 → Les mots vides (stopwords) comme 'le', 'la', 'de' sont souvent supprimés pour réduire le bruit.\n",
      "[ 5] score=0.0404  doc#50 → La normalisation Unicode (NFC/NFKD) affecte le traitement des diacritiques (é/ê/e).\n",
      "\n",
      "Query: 'pondérer le champ title plus que body' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5822  doc#38 → Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "[ 2] score=0.2745  doc#9 → La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "[ 3] score=0.2528  doc#22 → MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "[ 4] score=0.2354  doc#36 → Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "[ 5] score=0.2136  doc#25 → Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "\n",
      "Query: 'pondérer le champ title plus que body' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=1.0000  doc#38 → Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "[ 2] score=0.6980  doc#9 → La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "[ 3] score=0.6942  doc#36 → Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "[ 4] score=0.6916  doc#22 → MRR mesure l'inverse du rang de la première réponse correcte ; nDCG mesure des gains gradués.\n",
      "[ 5] score=0.6896  doc#25 → Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "\n",
      "Query: 'pondérer le champ title plus que body' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0333  doc#38 → Le champ 'title' a souvent plus de poids que 'body' dans les moteurs de recherche.\n",
      "[ 2] score=0.0304  doc#24 → La validation croisée et le split train/dev/test évitent le surapprentissage sur le corpus d'évaluation.\n",
      "[ 3] score=0.0302  doc#36 → Le reranking par un cross-encoder (ex. monoT5, cross-encoder-MiniLM) affine les top-k candidats.\n",
      "[ 4] score=0.0301  doc#25 → Le jugement de pertinence peut être humain, heuristique ou obtenu via pooling multi-systèmes.\n",
      "[ 5] score=0.0301  doc#9 → La pertinence peut être binaire ou graduée (gains), ce qui change la métrique optimale.\n",
      "\n",
      "Query: 'tf–idf (variante typographique) explication' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5149  doc#41 → TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 2] score=0.3941  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 3] score=0.3645  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 4] score=0.1755  doc#29 → Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "[ 5] score=0.0000  doc#52 → Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "\n",
      "Query: 'tf–idf (variante typographique) explication' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6123  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 2] score=0.5900  doc#41 → TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 3] score=0.4302  doc#29 → Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "[ 4] score=0.3708  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 5] score=0.3583  doc#16 → Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "\n",
      "Query: 'tf–idf (variante typographique) explication' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9929  doc#41 → TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 2] score=0.9601  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 3] score=0.8732  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 4] score=0.8298  doc#29 → Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "[ 5] score=0.7489  doc#16 → Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "\n",
      "Query: 'tf–idf (variante typographique) explication' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0331  doc#41 → TF–IDF (avec tiret demi-cadratin) est équivalent à TF-IDF (avec tiret standard) pour la plupart des implémentations.\n",
      "[ 2] score=0.0331  doc#3 → TF-IDF pondère fort les mots fréquents dans un document mais rares dans le corpus ; TF peut être brut, log-normalisé ou binaire.\n",
      "[ 3] score=0.0320  doc#17 → Gensim facilite le topic modeling (LDA) et des pipelines BoW/TF-IDF rapides.\n",
      "[ 4] score=0.0320  doc#29 → Les recettes de cuisine génèrent des listes d'ingrédients qui favorisent la pondération TF simple.\n",
      "[ 5] score=0.0308  doc#16 → Scikit-learn fournit CountVectorizer et TfidfVectorizer pour les représentations clairsemées.\n",
      "\n",
      "Query: 'embeding denses (typo) utilité' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6466  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 2] score=0.1712  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 3] score=0.1678  doc#6 → Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "[ 4] score=0.0000  doc#52 → Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "[ 5] score=0.0000  doc#13 → Le stemming de Porter tronque les suffixes, au risque d'ambiguïtés (ex. 'nation' et 'national').\n",
      "\n",
      "Query: 'embeding denses (typo) utilité' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6300  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 2] score=0.4539  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 3] score=0.4442  doc#7 → La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 4] score=0.4374  doc#6 → Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "[ 5] score=0.3125  doc#37 → La réduction de dimension (PCA) ou la quantification des vecteurs (PQ, IVFPQ) accélère l'ANN au prix d'une légère perte de rappel.\n",
      "\n",
      "Query: 'embeding denses (typo) utilité' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=1.0000  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 2] score=0.7966  doc#6 → Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "[ 3] score=0.7506  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 4] score=0.7477  doc#7 → La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 5] score=0.7319  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "\n",
      "Query: 'embeding denses (typo) utilité' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0333  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 2] score=0.0320  doc#6 → Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "[ 3] score=0.0312  doc#37 → La réduction de dimension (PCA) ou la quantification des vecteurs (PQ, IVFPQ) accélère l'ANN au prix d'une légère perte de rappel.\n",
      "[ 4] score=0.0307  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "[ 5] score=0.0306  doc#52 → Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "\n",
      "Query: 'Okapi-BM25 formule' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5015  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 2] score=0.3218  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=0.1464  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 4] score=0.1285  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 5] score=0.1241  doc#20 → Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "\n",
      "Query: 'Okapi-BM25 formule' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6431  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 2] score=0.5868  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 3] score=0.4999  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 4] score=0.4921  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 5] score=0.3956  doc#35 → La recherche hybride combine BM25 pour l'exact match et embeddings denses pour la similarité sémantique.\n",
      "\n",
      "Query: 'Okapi-BM25 formule' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9834  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 2] score=0.9402  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=0.8283  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 4] score=0.8278  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 5] score=0.8023  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "\n",
      "Query: 'Okapi-BM25 formule' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0331  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 2] score=0.0331  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "[ 3] score=0.0313  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "[ 4] score=0.0313  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 5] score=0.0311  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "\n",
      "Query: 'vector search sparse or dense' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.6043  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 2] score=0.2320  doc#7 → La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 3] score=0.2083  doc#20 → Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "[ 4] score=0.0869  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 5] score=0.0000  doc#52 → Une indexation incrémentale maintient la fraîcheur des résultats sans reconstruire tout l'index.\n",
      "\n",
      "Query: 'vector search sparse or dense' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.8790  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 2] score=0.7243  doc#7 → La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 3] score=0.6521  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 4] score=0.5335  doc#6 → Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "[ 5] score=0.4412  doc#37 → La réduction de dimension (PCA) ou la quantification des vecteurs (PQ, IVFPQ) accélère l'ANN au prix d'une légère perte de rappel.\n",
      "\n",
      "Query: 'vector search sparse or dense' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=1.0000  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 2] score=0.8427  doc#7 → La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 3] score=0.7511  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 4] score=0.7194  doc#6 → Les embeddings denses encodent le sens dans un espace vectoriel continu, utiles pour la recherche sémantique.\n",
      "[ 5] score=0.7116  doc#20 → Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "\n",
      "Query: 'vector search sparse or dense' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0333  doc#45 → Vector search peut être sparse or dense depending on the representation (mélange FR/EN).\n",
      "[ 2] score=0.0328  doc#7 → La recherche vectorielle peut être clairsemée (sparse) ou dense selon la représentation.\n",
      "[ 3] score=0.0308  doc#44 → La recherche de vecteurs denses peut tolérer les fautes: 'embeding denses' correspond souvent à 'embeddings denses'.\n",
      "[ 4] score=0.0306  doc#19 → Sentence-BERT (SBERT), E5, MPNet et ColBERT sont populaires pour l'indexation dense ou late interaction.\n",
      "[ 5] score=0.0304  doc#20 → Elasticsearch et OpenSearch implémentent BM25 par défaut et supportent la recherche hybride sparse+dense.\n",
      "\n",
      "Query: 'BM25 sans normalisation de longueur' — Sparse (tfidf)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.5377  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 2] score=0.3624  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 3] score=0.3453  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 4] score=0.3328  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 5] score=0.2420  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "\n",
      "Query: 'BM25 sans normalisation de longueur' — Dense (Sentence-Transformers)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.7922  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 2] score=0.7006  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 3] score=0.6876  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 4] score=0.5751  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 5] score=0.5552  doc#31 → Certains documents sont très courts: 'BM25 expliqué rapidement'.\n",
      "\n",
      "Query: 'BM25 sans normalisation de longueur' — Hybride (Somme pondérée, α=0.5)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.9763  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 2] score=0.9334  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 3] score=0.9103  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 4] score=0.8867  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 5] score=0.8284  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n",
      "\n",
      "Query: 'BM25 sans normalisation de longueur' — Hybride (RRF, k=60)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 1] score=0.0331  doc#43 → Une requête négative comme 'BM25 sans normalisation de longueur' nécessite des opérateurs booléens.\n",
      "[ 2] score=0.0325  doc#5 → BM25+ et BM25L sont des variantes qui ajustent la normalisation de longueur et l'offset des faibles fréquences.\n",
      "[ 3] score=0.0323  doc#4 → Okapi BM25 est un schéma de ranking basé sur la saturation de fréquence et la normalisation par longueur de document.\n",
      "[ 4] score=0.0323  doc#47 → Les paramètres clés de BM25 sont k1 et b ; k1 contrôle la saturation, b la normalisation de longueur.\n",
      "[ 5] score=0.0310  doc#42 → Okapi-BM25 et bm25 ranking désignent la même famille de fonctions de scoring.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TOP_N = 8  # candidats par canal\n",
    "ALPHA = 0.5\n",
    "K_RRF = 60\n",
    "SPARSE_METHOD = \"tfidf\"  # \"tfidf\" ou \"bm25\"\n",
    "\n",
    "for q in queries:\n",
    "    res = hybrid_search(q, sparse_method=SPARSE_METHOD, top_n_each=TOP_N, alpha=ALPHA, k_rrf=K_RRF)\n",
    "    # Affichage\n",
    "    show_ranking(f\"Query: {q!r} — Sparse ({SPARSE_METHOD})\", res[\"sparse_scores\"], k=5)\n",
    "    show_ranking(f\"Query: {q!r} — Dense (Sentence-Transformers)\", res[\"dense_scores\"], k=5)\n",
    "    show_ranking(f\"Query: {q!r} — Hybride (Somme pondérée, α={ALPHA})\", res[\"weighted_sum\"], k=5)\n",
    "    show_ranking(f\"Query: {q!r} — Hybride (RRF, k={K_RRF})\", res[\"rrf\"], k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68af800",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Visualisation rapide (facultatif)\n",
    "Pour une requête, on compare les **scores normalisés** de chaque canal et la **fusion**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56a0627a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "query = \"recherche d'information\"\n",
    "res = hybrid_search(query, sparse_method=\"tfidf\", top_n_each=8, alpha=0.5, k_rrf=60)\n",
    "\n",
    "# On affiche les 6 meilleurs documents selon la somme pondérée\n",
    "order = np.argsort(res[\"weighted_sum\"])[::-1][:6]\n",
    "labels = [f\"d{i}\" for i in order]\n",
    "s_sp = (res[\"sparse_scores\"] - res[\"sparse_scores\"].min()) / (res[\"sparse_scores\"].ptp() + 1e-12)\n",
    "s_de = (res[\"dense_scores\"] - res[\"dense_scores\"].min()) / (res[\"dense_scores\"].ptp() + 1e-12)\n",
    "s_ws = (res[\"weighted_sum\"] - res[\"weighted_sum\"].min()) / (res[\"weighted_sum\"].ptp() + 1e-12)\n",
    "\n",
    "x = np.arange(len(order))\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(x, s_sp[order], marker=\"o\", label=\"Sparse (norm.)\")\n",
    "plt.plot(x, s_de[order], marker=\"o\", label=\"Dense (norm.)\")\n",
    "plt.plot(x, s_ws[order], marker=\"o\", label=\"Fusion (norm.)\")\n",
    "plt.xticks(x, labels)\n",
    "plt.title(f\"Comparaison des scores normalisés — query: {query!r}\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
